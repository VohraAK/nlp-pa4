{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86afaff",
   "metadata": {},
   "source": [
    "# **NLP Assignment 4: LLM Applications**\n",
    "\n",
    "Welcome to this assignment! In this task, you will learn how to build **LLM applications from the ground up** using the **LangChain framework** — a widely adopted and industry-standard toolkit for developing AI-driven applications.\n",
    "\n",
    "---\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before starting the assignment, it is **strongly recommended** that you:\n",
    "\n",
    "- Review the provided manual thoroughly.\n",
    "- Attempt the preliminary exercises to become familiar with LangChain’s concepts and syntax.\n",
    "\n",
    "Working through these exercises independently will help you build a **solid foundation** in LLM application development and prepare you for real-world use cases in research and industry.\n",
    "\n",
    "---\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "- <span style=\"color:green\">**LCEL Syntax:**</span> You must use LangChain’s **LCEL syntax** for every task.  \n",
    "- <span style=\"color:green\">**Library Consistency:**</span> Use the same libraries and functions as demonstrated in the manual for Parts 1 and 2. While alternatives exist, using them may indicate a lack of understanding of the core material.  \n",
    "- <span style=\"color:green\">**Context Engineering:**</span> Starting from Part 1, Task 1, all chains must follow the principles of **Context Engineering using System Messages**, as detailed in the manual. Failure to adhere will result in a loss of marks.  \n",
    "- <span style=\"color:green\">**Reflective Questions:**</span> All reflective questions must be completed independently. The use of AI tools for these questions is strictly prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b70ce",
   "metadata": {},
   "source": [
    "# **Part 1: Building LLM pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09403b1",
   "metadata": {},
   "source": [
    "![LangChain Logo](figs/LangChain_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d02130",
   "metadata": {},
   "source": [
    "# **Introduction to LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395848e",
   "metadata": {},
   "source": [
    "### Setting up Gemini's API key\n",
    "\n",
    "Let's start by connecting to Gemini. You’ll need an API key from Google for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89089451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"  # or, feel free to use any LLM here\n",
    "llm = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0)\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508b1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the manual, test the code samples here. Write code on your own to grasp the core concept.\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a funny joke. The joke must be related to {pakistani_politician} Its okay to make fun of politicians! Make it quick, snappy and witty\")\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ea3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's Nawaz Sharif's favorite cure for political pressure?\n",
      "\n",
      "A first-class ticket to London for \"medical treatment\"!\n"
     ]
    }
   ],
   "source": [
    "## Invoke a chain that prompts the LLM to write a funny joke. The top 3 funniest jokes in the class would get a free cookie from me :)\n",
    "message = chain.invoke({\"pakistani_politician\": \"Nawaz Sharif\"})\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1502c",
   "metadata": {},
   "source": [
    "## Task 1: Prompt Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86eb82c",
   "metadata": {},
   "source": [
    "##### Converting Unstructured Data to a Structured Format\n",
    "We'll be dealing with a common problem that almost all data scientists face. How to convert unstructured data into meaningful data that can be easily processed? LLMs can be used for this task to convert textual data to a JSON object.\n",
    "\n",
    "Use the data from this Kaggle dataset for this task:\n",
    "[Resume Dataset](https://www.kaggle.com/datasets/gauravduttakiit/resume-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc872ef8",
   "metadata": {},
   "source": [
    "Your goal is to convert each resume in this dataset to a JSON object, which contains the following information:\n",
    "\n",
    "- candidate_name \n",
    "- candidate_skills (a list of relevant skills)\n",
    "- candidate_experience: (candidate experience in years)\n",
    "- candidate_profession\n",
    "\n",
    "You have to do so through **Zero-Shot, One-Shot and Few-Shot Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1554af",
   "metadata": {},
   "source": [
    "For this problem:\n",
    "- The Sample Inputs can be found under `datasets/part1/task1/resumes`\n",
    "- The Sample Outputs are in the JSON file `datasets/part1/task1/resume_outputs.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a1d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sample inputs\n",
    "RESUMES_PATH = \"datasets/part1/task1/resumes\"\n",
    "\n",
    "resume_files = glob.glob(f\"{RESUMES_PATH}/*.txt\")\n",
    "sample_resumes = []\n",
    "for file_path in resume_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sample_resumes.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8465ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**Resume 4: Data Analyst**\\n\\n**Jessica Park**\\nChicago, IL | (555) 987-6543 | jessica.park@email.com | linkedin.com/in/jessicapark\\n\\n**Summary**\\nAnalytical and detail-oriented Data Analyst with 2 years of experience transforming complex datasets into actionable insights. Proficient in SQL, data visualization, and statistical analysis. Passionate about using data to drive business strategy and improve operational efficiency.\\n\\n**Professional Experience**\\n\\n*Data Analyst*, Retail Insights Corp., Chicago, IL | 2022 – Present\\n*   Wrote complex SQL queries to extract and analyze sales, customer, and inventory data from a centralized data warehouse.\\n*   Created interactive Tableau dashboards for the executive team, tracking KPIs and identifying sales trends, which contributed to a 15% reduction in excess inventory.\\n*   Performed A/B test analysis for marketing campaigns, providing recommendations that improved conversion rates by 8%.\\n*   Assisted in building and maintaining ETL pipelines using Python (Pandas) to automate monthly reporting.\\n*   Collaborated with cross-functional teams to define data requirements and deliver reports on schedule.\\n\\n*Data Analysis Intern*, Urban Analytics, Chicago, IL | 2021 – 2022\\n*   Cleaned and validated large datasets for accuracy and completeness.\\n*   Supported senior analysts with ad-hoc data requests and preliminary analysis.\\n*   Created basic visualizations in Excel and PowerPoint for client presentations.\\n\\n**Skills**\\n*   **Programming & Databases:** SQL (Advanced), Python (Pandas, NumPy), R\\n*   **Visualization & BI Tools:** Tableau, Power BI, Excel (PivotTables, Charts)\\n*   **Analysis:** Statistical Analysis, A/B Testing, Data Cleaning, Trend Analysis, Reporting\\n\\n**Education**\\nBachelor of Science in Statistics | University of Illinois at Chicago | 2021',\n",
       " '**Resume 5: Customer Service Representative**\\n\\n**Marcus Johnson**\\nPhoenix, AZ | (555) 246-8101 | marcus.johnson@email.com\\n\\n**Summary**\\nA reliable and empathetic Customer Service Representative with 1 year of experience in a high-volume call center environment. Excellent communication and problem-solving skills with a proven ability to de-escalate tense situations and build customer loyalty. Fast learner adept at using CRM software.\\n\\n**Professional Experience**\\n\\n*Customer Service Representative*, ConnectCom Solutions, Phoenix, AZ | 2023 – Present\\n*   Handle an average of 60+ customer inquiries daily via phone and email regarding billing, technical support, and account management.\\n*   Achieved a 95% customer satisfaction rating, consistently exceeding the team target of 90%.\\n*   Utilized Zendesk to log, track, and resolve customer issues efficiently.\\n*   Successfully de-escalated frustrated customers, turning negative experiences into positive ones.\\n*   Identified and escalated recurring technical issues to the engineering team, contributing to a long-term product fix.\\n\\n**Skills**\\n*   **Customer Service:** Conflict Resolution, Active Listening, Customer Retention, Empathy\\n*   **Software:** Zendesk, Microsoft Office Suite, G-Suite\\n*   **Soft Skills:** Communication, Problem-Solving, Patience, Time Management, Teamwork\\n\\n**Education**\\nHigh School Diploma | North Canyon High School | 2022',\n",
       " '**Resume 1: Senior Software Engineer**\\n\\n**Alex Chen**\\nSan Francisco, CA | (123) 456-7890 | alex.chen@email.com | linkedin.com/in/alexchen\\n\\n**Summary**\\nA seasoned Senior Software Engineer with over 10 years of experience in designing, developing, and scaling high-performance web applications. Proven ability to lead technical projects, mentor junior engineers, and drive the adoption of modern software architecture and DevOps practices. Deep expertise in the JavaScript/TypeScript ecosystem and cloud platforms.\\n\\n**Professional Experience**\\n\\n*Senior Software Engineer*, TechFlow Inc., San Francisco, CA | 2018 – Present\\n*   Led the redesign of a monolithic payment processing service into a microservices architecture, improving system uptime from 99.9% to 99.99% and reducing latency by 40%.\\n*   Architected and implemented a real-time data dashboard using React, Node.js, and WebSockets, serving over 1 million daily active users.\\n*   Mentored 4 junior and mid-level engineers, conducting code reviews and facilitating their technical growth.\\n*   Spearheaded the adoption of TypeScript across the front-end codebase, reducing runtime errors by 60%.\\n*   Implemented comprehensive CI/CD pipelines using Docker, Jenkins, and Kubernetes, decreasing deployment times by 70%.\\n\\n*Software Engineer*, Innovate Solutions, Austin, TX | 2014 – 2018\\n*   Developed and maintained customer-facing features for a large-scale SaaS product using AngularJS and Java/Spring Boot.\\n*   Collaborated with product managers and designers in an Agile environment to deliver user stories on schedule.\\n*   Wrote unit and integration tests, achieving 90% code coverage and improving overall code quality.\\n\\n**Skills**\\n*   **Programming Languages:** JavaScript (Expert), TypeScript (Expert), Python (Proficient), Java (Proficient)\\n*   **Frameworks & Libraries:** React, Node.js, Express.js, Next.js, Spring Boot\\n*   **Databases:** PostgreSQL, MongoDB, Redis\\n*   **Tools & Platforms:** Docker, Kubernetes, AWS (EC2, S3, RDS, Lambda), Jenkins, Git, JIRA\\n\\n**Education**\\nBachelor of Science in Computer Science | University of Texas at Austin | 2014',\n",
       " \"**Resume 2: Marketing Manager**\\n\\n**Bianca Rossi**\\nNew York, NY | (987) 654-3210 | bianca.rossi@email.com | linkedin.com/in/biancarossi\\n\\n**Summary**\\nData-driven Marketing Manager with 7 years of experience in developing and executing successful multi-channel marketing strategies. Expertise in brand development, digital advertising, and marketing automation, with a proven track record of increasing lead generation and revenue growth.\\n\\n**Professional Experience**\\n\\n*Marketing Manager*, Global Brand Co., New York, NY | 2019 – Present\\n*   Developed and executed the annual marketing strategy with a $2M budget, resulting in a 35% increase in qualified leads and a 20% uplift in sales revenue.\\n*   Managed a team of 5 marketing specialists across content, SEO, and digital advertising.\\n*   Launched 3 new product lines, creating full-funnel marketing campaigns that exceeded sales targets by 25%.\\n*   Implemented and optimized HubSpot for marketing automation, leading to a 50% increase in lead nurturing efficiency.\\n*   Oversaw the company's social media presence, growing the organic following by 200% and increasing engagement by 150%.\\n\\n*Marketing Specialist*, Spark Digital, Boston, MA | 2016 – 2019\\n*   Executed paid digital campaigns (Google Ads, LinkedIn) with an average ROI of 400%.\\n*   Produced high-converting content including whitepapers, case studies, and blog posts.\\n*   Conducted market research and competitive analysis to inform campaign targeting.\\n\\n**Skills**\\n*   **Digital Marketing:** SEO/SEM, Google Analytics, PPC, Social Media Marketing (LinkedIn, Facebook, Instagram), Email Marketing\\n*   **Tools:** HubSpot, Salesforce, Google Workspace, Asana, Hootsuite, Canva\\n*   **Strategy:** Brand Strategy, Content Strategy, Market Research, Budget Management, Team Leadership\\n\\n**Education**\\nBachelor of Arts in Communications | Boston University | 2016\",\n",
       " \"**Resume 3: Certified Welder**\\n\\n**David Miller**\\nDetroit, MI | (555) 123-4567 | david.miller@email.com\\n\\n**Summary**\\nSkilled and safety-conscious Welder with 4 years of hands-on experience in MIG, TIG, and Stick welding. Proficient in reading blueprints, operating welding equipment, and performing quality checks. Seeking to apply technical skills and a strong work ethic in a manufacturing or construction role.\\n\\n**Professional Experience**\\n\\n*Welder*, Great Lakes Fabrication, Detroit, MI | 2020 – Present\\n*   Performed MIG and TIG welding on stainless steel and aluminum components for industrial machinery.\\n*   Consistently interpreted complex engineering blueprints and schematics to meet precise specifications.\\n*   Operated and maintained welding machinery, including plasma cutters and thermal lances.\\n*   Conducted visual and structural tests on welds to ensure they met company and industry standards (AWS D1.1).\\n*   Adhered strictly to all safety protocols, maintaining a perfect safety record with zero incidents.\\n\\n*Welder's Apprentice*, Motor City Metalworks, Detroit, MI | 2019 – 2020\\n*   Assisted senior welders with material preparation, setup, and finishing.\\n*   Learned and practiced fundamental welding techniques under supervision.\\n*   Maintained a clean and organized work environment.\\n\\n**Skills**\\n*   **Welding Techniques:** MIG (Expert), TIG (Proficient), Stick (SMAW) (Proficient)\\n*   **Materials:** Mild Steel, Stainless Steel, Aluminum\\n*   **Equipment:** Oxy-Acetylene Torch, Plasma Cutter, Grinders, Saws\\n*   **Other:** Blueprint Reading, Welding Symbols, Safety Procedures (OSHA), Quality Control, Measurements\\n\\n**Certifications**\\n*   AWS Certified Welder | American Welding Society | 2019\\n\\n**Education**\\nWelding Technology Certificate | Detroit Vocational College | 2019\\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4ae497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 962 entries, 0 to 961\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  962 non-null    object\n",
      " 1   Resume    962 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# load dataset from Kaggle\n",
    "KAGGLE_RESUME_PATH = \"datasets/part1/task1/kaggle_resumes/UpdatedResumeDataSet.csv\"\n",
    "\n",
    "resumes_df = pd.read_csv(KAGGLE_RESUME_PATH)\n",
    "\n",
    "resumes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357e2d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Resume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f987af76-4281-44b9-b7dd-3d670a5b59ef",
       "rows": [
        [
         "0",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "1",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "2",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "3",
         "Data Science",
         "Skills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\nâ¢ Extract data from client systems across geographies.\r\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\nâ¢ Gather data large enough to capture all English words\r\nâ¢ Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop ETL for data flow\r\nâ¢ Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop and deploy analytical models.\r\nâ¢ Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\nâ¢ Design & Develop HANA models for decomposition.\r\nâ¢ Develop data flow for forecast.\r\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\r\nâ¢ Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\nâ¢ Involved in information gather phase.\r\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\r\nâ¢ Created procedures in HANA Database.\r\nâ¢ Took ownership and developed Dashboard functionality.\r\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\r\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\nâ¢ Responsible for Designing, developing and Normalization of database tables\r\nâ¢ Experience in performance tuning using SQL profiler.\r\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "4",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "5",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "6",
         "Data Science",
         "Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - â¢ Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\nâ¢ Responsible for loading, extracting and validation of client data.\r\nâ¢ Worked on manipulating, cleaning & processing data using python.\r\nâ¢ Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - â¢ Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\nâ¢ Manipulating, cleansing & processing data using Python, Excel and R.\r\nâ¢ Analyzed raw data, drawing conclusions & developing recommendations.\r\nâ¢ Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "7",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "8",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "9",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "10",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "11",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "12",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "13",
         "Data Science",
         "Skills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\nâ¢ Extract data from client systems across geographies.\r\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\nâ¢ Gather data large enough to capture all English words\r\nâ¢ Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop ETL for data flow\r\nâ¢ Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop and deploy analytical models.\r\nâ¢ Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\nâ¢ Design & Develop HANA models for decomposition.\r\nâ¢ Develop data flow for forecast.\r\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\r\nâ¢ Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\nâ¢ Involved in information gather phase.\r\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\r\nâ¢ Created procedures in HANA Database.\r\nâ¢ Took ownership and developed Dashboard functionality.\r\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\r\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\nâ¢ Responsible for Designing, developing and Normalization of database tables\r\nâ¢ Experience in performance tuning using SQL profiler.\r\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "14",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "15",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "16",
         "Data Science",
         "Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - â¢ Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\nâ¢ Responsible for loading, extracting and validation of client data.\r\nâ¢ Worked on manipulating, cleaning & processing data using python.\r\nâ¢ Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - â¢ Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\nâ¢ Manipulating, cleansing & processing data using Python, Excel and R.\r\nâ¢ Analyzed raw data, drawing conclusions & developing recommendations.\r\nâ¢ Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "17",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "18",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "19",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "20",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "21",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "22",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "23",
         "Data Science",
         "Skills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\nâ¢ Extract data from client systems across geographies.\r\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\nâ¢ Gather data large enough to capture all English words\r\nâ¢ Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop ETL for data flow\r\nâ¢ Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop and deploy analytical models.\r\nâ¢ Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\nâ¢ Design & Develop HANA models for decomposition.\r\nâ¢ Develop data flow for forecast.\r\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\r\nâ¢ Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\nâ¢ Involved in information gather phase.\r\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\r\nâ¢ Created procedures in HANA Database.\r\nâ¢ Took ownership and developed Dashboard functionality.\r\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\r\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\nâ¢ Responsible for Designing, developing and Normalization of database tables\r\nâ¢ Experience in performance tuning using SQL profiler.\r\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "24",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "25",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "26",
         "Data Science",
         "Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - â¢ Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\nâ¢ Responsible for loading, extracting and validation of client data.\r\nâ¢ Worked on manipulating, cleaning & processing data using python.\r\nâ¢ Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - â¢ Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\nâ¢ Manipulating, cleansing & processing data using Python, Excel and R.\r\nâ¢ Analyzed raw data, drawing conclusions & developing recommendations.\r\nâ¢ Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "27",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "28",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "29",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "30",
         "Data Science",
         "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \r\n\r\nData Science Assurance Associate \r\n\r\nData Science Assurance Associate - Ernst & Young LLP\r\nSkill Details \r\nJAVASCRIPT- Exprience - 24 months\r\njQuery- Exprience - 24 months\r\nPython- Exprience - 24 monthsCompany Details \r\ncompany - Ernst & Young LLP\r\ndescription - Fraud Investigations and Dispute Services   Assurance\r\nTECHNOLOGY ASSISTED REVIEW\r\nTAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\r\n* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\r\n* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\r\n* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\r\n\r\nTools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\r\n\r\nMULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\r\nTEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\r\n* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\r\n* Created customized tableau dashboards for effective reporting and visualizations.\r\nCHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\r\n* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\r\n* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\r\n\r\nTools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\r\n\r\nINFORMATION GOVERNANCE\r\nOrganizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\r\n* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\r\n* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\r\n* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\r\nTools & Technologies: Python, Flask, Elastic Search, Kibana\r\n\r\nFRAUD ANALYTIC PLATFORM\r\nFraud Analytics and investigative platform to review all red flag cases.\r\nâ¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\r\n* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\r\nTools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js"
        ],
        [
         "31",
         "Data Science",
         "Education Details \r\nMay 2013 to May 2017 B.E   UIT-RGPV\r\nData Scientist \r\n\r\nData Scientist - Matelabs\r\nSkill Details \r\nPython- Exprience - Less than 1 year months\r\nStatsmodels- Exprience - 12 months\r\nAWS- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nSklearn- Exprience - Less than 1 year months\r\nScipy- Exprience - Less than 1 year months\r\nKeras- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Matelabs\r\ndescription - ML Platform for business professionals, dummies and enthusiasts.\r\n60/A Koramangala 5th block,\r\nAchievements/Tasks behind sukh sagar, Bengaluru,\r\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\r\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reduction.\r\nDeployed automated classification and regression model.\r\nlinkedin.com/in/aditya-rathore-\r\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\r\nProphet.\r\nWorked on meta-feature extracting problem.\r\ngithub.com/rathorology\r\nImplemented a state of the art research paper on outlier detection for mixed attributes.\r\ncompany - Matelabs\r\ndescription - "
        ],
        [
         "32",
         "Data Science",
         "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp, MySQL-Basics, Python Software Packages Interpreters-Anaconda, Python2, Python3, Pycharm, Java IDE-Eclipse Operating Systems Windows, Ubuntu, Debian-Kali Linux Education Details \r\nJanuary 2019 B.Tech. Electrical and Electronics Engineering  Manipal Institute of Technology\r\nJanuary 2015    DEEKSHA CENTER\r\nJanuary 2013    Little Flower Public School\r\nAugust 2000    Manipal Academy of Higher\r\nDATA SCIENCE \r\n\r\nDATA SCIENCE AND ELECTRICAL ENTHUSIAST\r\nSkill Details \r\nData Analysis- Exprience - Less than 1 year months\r\nexcel- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nmathematics- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year months\r\nElectrical Engineering- Exprience - Less than 1 year months\r\nSql- Exprience - Less than 1 year monthsCompany Details \r\ncompany - THEMATHCOMPANY\r\ndescription - I am currently working with a Casino based operator(name not to be disclosed) in Macau.I need to segment the customers who visit their property based on the value the patrons bring into the company.Basically prove that the segmentation can be done in much better way than the current system which they have with proper numbers to back it up.Henceforth they can implement target marketing strategy to attract their customers who add value to the business."
        ],
        [
         "33",
         "Data Science",
         "Skills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \r\nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\r\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\r\nData Science Consultant \r\n\r\nConsultant - Deloitte USI\r\nSkill Details \r\nLINEAR PROGRAMMING- Exprience - 6 months\r\nRETAIL- Exprience - 6 months\r\nRETAIL MARKETING- Exprience - 6 months\r\nSCM- Exprience - 6 months\r\nSQL- Exprience - Less than 1 year months\r\nDeep Learning- Exprience - Less than 1 year months\r\nMachine learning- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nR- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Deloitte USI\r\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\r\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\r\nKey Responsibilities:\r\nâ¢ Extract data from client systems across geographies.\r\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\r\nTechnical Environment: R, Tableau.\r\n\r\nIndustry: Cross Industry\r\nService Area: Cross Industry - Products\r\nProject Name: Handwriting recognition\r\nConsultant: 3 months.\r\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\r\nRole: I was developing sentence correction functionality.\r\nKey Responsibilities:\r\nâ¢ Gather data large enough to capture all English words\r\nâ¢ Train LSTM models on words.\r\nTechnical Environment: Python.\r\n\r\nIndustry: Finance\r\nService Area: Financial Services - BI development Project Name: SWIFT\r\nConsultant: 8 months.\r\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\r\nfinancial reports to respective departments. Reporting also included forecasting expenses.\r\nRole: I was leading the offshore team.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop ETL for data flow\r\nâ¢ Validate various reports.\r\nTechnical Environment: SAP HANA, Tableau, SAP AO.\r\n\r\nIndustry: Healthcare Analytics\r\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\r\nConsultant: 2 months.\r\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\r\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\r\nmodels for insights.\r\nKey Responsibilities:\r\nâ¢ Design & Develop data models for reporting.\r\nâ¢ Develop and deploy analytical models.\r\nâ¢ Validate various reports.\r\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\r\n\r\nIndustry: FMCG\r\nService Area: Trade & Promotion\r\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\r\nThe project involved setting up of CRM and CBP modules.\r\nRole: I was involved in key data decomposition activities and setting up the base for future year\r\nforecast. Over the course of the project I developed various models and carried out key\r\nperformance improvements.\r\nKey Responsibilities:\r\nâ¢ Design & Develop HANA models for decomposition.\r\nâ¢ Develop data flow for forecast.\r\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\r\nâ¢ Validate various reports in BOBJ.\r\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\r\n\r\nInternal Initiative Industry: FMCG\r\nCustomer Segmentation and RFM analysis Consultant; 3 months.\r\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\r\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\r\n\r\nIndustry: Telecom Invoice state detection Consultant; 1 months.\r\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\r\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\r\nreduction by 60%.\r\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\r\n\r\nAccenture Experience\r\nIndustry: Analytics - Cross Industry\r\nIn Process Analytics for SAP Senior Developer; 19 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\r\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\r\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\r\nKey Responsibilities:\r\nâ¢ Involved in information gather phase.\r\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\r\nCalculation View.\r\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\r\nâ¢ Created procedures in HANA Database.\r\nâ¢ Took ownership and developed Dashboard functionality.\r\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\r\nTechnical Environment: R, SAP HANA, T-SQL.\r\nIndustry: Cross Industry\r\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\r\nAccenture Solutions Pvt. Ltd., India\r\nRole: I have taken care of all development activities for the ATAS tool and have also completed\r\nvarious deployments of the product.\r\nApart from these activities I was also actively involved in maintenance of the database servers\r\n(Production & Quality)\r\nKey Responsibilities:\r\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\r\ninteracting with business and further transform all requirements to generate attribute\r\nmapping documents and reviewing mapping specification documentation\r\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\r\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\r\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\r\nâ¢ Responsible for Designing, developing and Normalization of database tables\r\nâ¢ Experience in performance tuning using SQL profiler.\r\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\r\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\r\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL."
        ],
        [
         "34",
         "Data Science",
         "Education Details \r\n MCA   YMCAUST,  Faridabad,  Haryana\r\nData Science internship \r\n\r\n\r\nSkill Details \r\nData Structure- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nData Analysis- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nCore Java- Exprience - Less than 1 year months\r\nDatabase Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Itechpower\r\ndescription - "
        ],
        [
         "35",
         "Data Science",
         "SKILLS C Basics, IOT, Python, MATLAB, Data Science, Machine Learning, HTML, Microsoft Word, Microsoft Excel, Microsoft Powerpoint. RECOGNITION Academic Secured First place in B.Tech.Education Details \r\nAugust 2014 to May 2018 B.Tech.  Ghatkesar, Andhra Pradesh Aurora's Scientific and Technological Institute\r\nJune 2012 to May 2014  Secondary Education Warangal, Telangana SR Junior College\r\nData Science \r\n\r\n\r\nSkill Details \r\nMS OFFICE- Exprience - Less than 1 year months\r\nC- Exprience - Less than 1 year months\r\nmachine learning- Exprience - Less than 1 year months\r\ndata science- Exprience - Less than 1 year months\r\nMatlab- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "36",
         "Data Science",
         "Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world solutions. Being a strong advocator of augmented era, where human capabilities are enhanced by machines, Fahed is passionate about bringing business concepts in area of machine learning, AI, robotics etc., to real life solutions.Education Details \r\nJanuary 2017 B. Tech Computer Science & Engineering Mohali, Punjab Indo Global College of Engineering\r\nData Science Consultant \r\n\r\nData Science Consultant - Datamites\r\nSkill Details \r\nMACHINE LEARNING- Exprience - 13 months\r\nPYTHON- Exprience - 24 months\r\nSOLUTIONS- Exprience - 24 months\r\nDATA SCIENCE- Exprience - 24 months\r\nDATA VISUALIZATION- Exprience - 24 months\r\nTableau- Exprience - 24 monthsCompany Details \r\ncompany - Datamites\r\ndescription - â¢ Analyzed and processed complex data sets using advanced querying, visualization and analytics tools.\r\nâ¢ Responsible for loading, extracting and validation of client data.\r\nâ¢ Worked on manipulating, cleaning & processing data using python.\r\nâ¢ Used Tableau for data visualization.\r\ncompany - Heretic Solutions Pvt Ltd\r\ndescription - â¢ Worked closely with business to identify issues and used data to propose solutions for effective decision making.\r\nâ¢ Manipulating, cleansing & processing data using Python, Excel and R.\r\nâ¢ Analyzed raw data, drawing conclusions & developing recommendations.\r\nâ¢ Used machine learning tools and statistical techniques to produce solutions to problems."
        ],
        [
         "37",
         "Data Science",
         "Education Details \r\n B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\nData Science \r\n\r\nData Science\r\nSkill Details \r\nNumpy- Exprience - Less than 1 year months\r\nMachine Learning- Exprience - Less than 1 year months\r\nTensorflow- Exprience - Less than 1 year months\r\nScikit- Exprience - Less than 1 year months\r\nPython- Exprience - Less than 1 year months\r\nGCP- Exprience - Less than 1 year months\r\nPandas- Exprience - Less than 1 year months\r\nNeural Network- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Wipro\r\ndescription - Bhawana Aggarwal\r\nE-Mail:bhawana.chd@gmail.com\r\nPhone: 09876971076\r\nVVersatile, high-energy professional targeting challenging assignments in Machine\r\nPROFILE SUMMARY\r\nâª An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability.\r\nTECHNICAL SKILLS\r\nProgramming Languages Python, C\r\nLibraries Seaborn, Numpy, Pandas, Cufflinks, Matplotlib\r\nAlgorithms\r\nKNN, Decision Tree, Linear regression, Logistic Regression, Neural Networks, K means clustering,\r\nTensorflow, SVM\r\nDatabases SQL, Oracle\r\nOperating Systems Linux, Window\r\nDevelopment Environments NetBeans, Notebooks, Sublime\r\nTicketing tools Service Now, Remedy\r\nEducation\r\nUG Education:\r\nB.Tech (Computer Science) from Rayat and Bahra Institute of Engineering and Biotechnology passed with 78.4%in\r\n2016.\r\nSchooling:\r\nXII in 2012 from Moti Ram Arya Sr. Secondary School(Passed with 78.4%)\r\nX in 2010 from Valley Public School (Passed with 9.4 CGPA)\r\nWORK EXPERINCE\r\nTitle : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\nOTHER PROJECTS\r\nTitle : Diabetes Detection\r\nBrief : Developed the software which can detect whether the person is suffering from Diabetes or not and got the third\r\nprize in it.\r\nTRAINING AND CERTIFICATIONS\r\nTitle: Python Training, Machine Learning, Data Science, Deep Learning\r\nOrganization: Udemy, Coursera (Machine Learning, Deep Learning)\r\nPersonal Profile\r\nFatherâs Name :Mr. Tirlok Aggarwal\r\nLanguage Known : English & Hindi\r\nMarital Status :Single\r\nDate of Birth(Gender):1993-12-20(YYYY-MM-DD) (F)\r\ncompany - Wipro\r\ndescription - Developing programs in Python.\r\ncompany - Wipro\r\ndescription - Title : Wipro Neural Intelligence Platform\r\nTeam Size : 5\r\nBrief: Wiproâs Neural Intelligence Platform harnesses the power of automation and artificial intelligence\r\ntechnologiesânatural language processing (NLP), cognitive, machine learning, and analytics. The platform\r\ncomprises three layers: a data engagement platform that can easily access and manage multiple structured and\r\nunstructured data sources; an âintent assessment and reasoningâ engine that includes sentiment and predictive\r\nanalytics; and a deep machine learning engine that can sense, act, and learn over time. The project entailed\r\nautomating responses to user queries at the earliest. The Monster Bot using the power of Deep Machine Learning,\r\nNLP to handle such queries. User can see the how their queries can be answered quickly like allL1 activities can be\r\neliminated.\r\nEntity Extractor -> This involves text extraction and NLP for fetching out important information from the text like\r\ndates, names, places, contact numbers etc. This involves Regex, Bluemix NLU apiâs and machine learning using\r\nTensor flow for further learning of new entities.\r\nClassifier ->This involves the classifications of classes, training of dataset and predicting the output using the SKLearn\r\nclassifier (MNB, SVM, SGD as Classifier) and SGD for the optimization to map the user queries with the best\r\nsuited response and make the system efficient.\r\nNER: A Deep Learning NER Model is trained to extract the entities from the text. Entities like Roles, Skills,\r\nOrganizations can be extracted from raw text. RNN(LSTM) Bidirectional model is trained for extracting such entities\r\nusing Keras TensorFlow framework.\r\ncompany - Wipro Technologies\r\ndescription - An IT professional with knowledge and experience of 2 years in Wipro Technologies in Machine\r\nLearning, Deep Learning, Data Science, Python, Software Development.\r\nâª Skilled in managing end-to-end development and software products / projects from inception, requirement\r\nspecs, planning, designing, implementation, configuration and documentation.\r\nâª Knowledge on Python , Machine Learning, Deep Learning, data Science, Algorithms, Neural Network,\r\nNLP, GCP.\r\nâª Knowledge on Python Libraries like Numpy, Pandas, Seaborn , Matplotlib, Cufflinks.\r\nâª Knowledge on different algorithms in Machine learning like KNN, Decision Tree, Bias variance Trade off,\r\nSupport vector Machine(SVM),Logistic Regression, Neural networks.\r\nâª Have knowledge on unsupervised, Supervised and reinforcement data.\r\nâª Programming experience in relational platforms like MySQL,Oracle.\r\nâª Have knowledge on Some programming language like C++,Java.\r\nâª Experience in cloud based environment like Google Cloud.\r\nâª Working on different Operating System like Linux, Ubuntu, Windows.\r\nâª Good interpersonal and communication skills.\r\nâª Problem solving skills with the ability to think laterally, and to think with a medium term and long term\r\nperspective\r\nâª Flexibility and an open attitude to change.\r\nâª Ability to create, define and own frameworks with a strong emphasis on code reusability."
        ],
        [
         "38",
         "Data Science",
         "Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\nJanuary 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\nJanuary 2010 B.E. computer science Bhopal, Madhya Pradesh RKDF Institute of Science and Technology College of Engineering\r\nJanuary 2006 Polytechnic Information Technology Vidisha, Madhya Pradesh SATI Engineering College in Vidisha\r\nJanuary 2003 M.tech Thesis Detail  BMCH School in Ganj basoda\r\nData science \r\n\r\nI have six month experience in Data Science. Key Skills: - Experience in Machine Learning, Deep Leaning, NLP, Python, SQL, Web Scraping Good knowledge in computer subjects and ability to update\r\nSkill Details \r\nExperience in Machine Learning, Deep Learning, NLP, Python, SQL, Web Crawling, HTML,CSS.- Exprience - Less than 1 year monthsCompany Details \r\ncompany - RNT.AI Technology Solution\r\ndescription - Text classification using Machine learning Algorithms with python.\r\nPractical knowledge of Deep learning algorithms such as Â Recurrent Neural Networks(RNN).\r\nDevelop custom data models and algorithms to apply to dataset\r\nExperience with Python packages like Pandas, Scikit-learn, Tensor Flow, Numpy, Matplotliv, NLTK.\r\nComfort with SQL, Â MYSQL\r\nSentiment analysis.\r\nÂ Apply leave Dataset using classification technique like Tf--idf , LSA with cosine similarity using Machine learning Algorithms.\r\nWeb crawling using Selenium web driver and Beautiful Soup with python.\r\ncompany - Life Insurance Corporation of India Bhopal\r\ndescription - Ã¼Â Explaining policy features and the benefits\r\nÃ¼ Updated knowledge of life insurance products and shared with customers"
        ],
        [
         "39",
         "Data Science",
         "Expertise â Data and Quantitative Analysis â Decision Analytics â Predictive Modeling â Data-Driven Personalization â KPI Dashboards â Big Data Queries and Interpretation â Data Mining and Visualization Tools â Machine Learning Algorithms â Business Intelligence (BI) â Research, Reports and Forecasts Education Details \r\n PGP in Data Science  Mumbai, Maharashtra Aegis School of data science & Business\r\n B.E. in Electronics & Communication Electronics & Communication Indore, Madhya Pradesh IES IPS Academy\r\nData Scientist \r\n\r\nData Scientist with PR Canada\r\nSkill Details \r\nAlgorithms- Exprience - 6 months\r\nBI- Exprience - 6 months\r\nBusiness Intelligence- Exprience - 6 months\r\nMachine Learning- Exprience - 24 months\r\nVisualization- Exprience - 24 months\r\nspark- Exprience - 24 months\r\npython- Exprience - 36 months\r\ntableau- Exprience - 36 months\r\nData Analysis- Exprience - 24 monthsCompany Details \r\ncompany - Aegis school of Data Science & Business\r\ndescription - Mostly working on industry project for providing solution along with Teaching Appointments: Teach undergraduate and graduate-level courses in Spark and Machine Learning as an adjunct faculty member at Aegis School of Data Science, Mumbai (2017 to Present)\r\ncompany - Aegis school of Data & Business\r\ndescription - Data Science Intern, Nov 2015 to Jan 2016\r\n\r\nFurnish executive leadership team with insights, analytics, reports and recommendations enabling effective strategic planning across all business units, distribution channels and product lines.\r\n\r\nâ Chat Bot using AWS LEX and Tensor flow  Python\r\nThe goal of project creates a chat bot for an academic institution or university to handle queries related courses offered by that institute. The objective of this task is to reduce human efforts as well as reduce man made errors. Even by this companies handle their client 24x7. In this case companies are academic institutions and clients are participants or students.\r\nâ Web scraping using Selenium web driver   Python\r\nThe task is to scrap the data from the online messaging portal in a text format and have to find the pattern form it.\r\nâ Data Visualization and Data insights   Hadoop Eco System, Hive, PySpark, QlikSense\r\nThe goal of this project is to build a Business Solutions to a Internet Service Provider Company, like handling data which is generated per day basis, for that we have to visualize that data and find the usage pattern form it and have a generate a reports.\r\nâ Image Based Fraud Detection   Microsoft Face API, PySpark, Open CV\r\nThe main goal of project is Recognize similarity for a face to given Database images. Face recognition is the recognizing a special face from set of different faces. Face is extracted and then compared with the database Image if that Image recognized then the person already applied for loan from somewhere else and now hiding his or her identity, this is how we are going to prevent the frauds in the initial stage itself.\r\nâ Churn Analysis for Internet Service Provider   R, Python, Machine Learning, Hadoop\r\nThe objective is to identify the customer who is likely to churn in a given period of time; we have to pretend the customer giving incentive offers.\r\nâ Sentiment Analysis   Python, NLP, Apache Spark service in IBM Bluemix.\r\nThis project is highly emphasis on tweets from Twitter data were taken for mobile networks service provider to do a sentiment analysis and analyze whether the expressed opinion was positive, negative or neutral, capture the emotions of the tweets and comparative analysis.\r\n\r\nQuantifiable Results:\r\nâ Mentored 7-12 Data Science Enthusiast each year that have all since gone on to graduate school in Data Science and Business Analytics.\r\nâ Reviewed and evaluated 20-40 Research Papers on Data Science for one of the largest Data Science Conference called Data Science Congress by Aegis School of Business Mumbai.\r\nâ Heading a solution providing organization called Data Science Delivered into Aegis school of Data Science Mumbai and managed 4-5 live projects using Data Science techniques.\r\nâ Working for some social cause with the help of Data Science for Social Goods Committee, where our team developed a product called \"Let's find a missing Child\" for helping society.\r\ncompany - IBM India pvt ltd\r\ndescription - Mostly worked on blumix and IBM Watson for Data science."
        ],
        [
         "40",
         "HR",
         "TECHNICAL SKILLS â¢ Typewriting â¢ TORA â¢ SPSSEducation Details \r\nJanuary 2017 MBA  Chidambaram, Tamil Nadu SNS College of Engineering\r\nJanuary 2014 HSC   at SAV Higher Secondary School\r\n MBA   SNS College of Engineering\r\n SSLC Finance  at Kamaraj Matriculation School\r\nHR \r\n\r\n\r\nSkill Details \r\nHuman resource, Finance- Exprience - Less than 1 year monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "41",
         "HR",
         "I.T. Skills â¢ Windows XP, Ms Office (Word, Excel: Look-ups; Pivot table; other basic functions ; Power Point) â¢ Saral Payment Package- payroll software â¢ Internet ApplicationsEducation Details \r\nJanuary 2006 Bachelor in Hospitality Management International Hospitality Management  Queen Margaret University Edinburg\r\nJanuary 2006 diploma Hotel Management  International Institute of Hotel Management\r\nHR \r\n\r\n\r\nSkill Details \r\nHr Management- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Atri Developers\r\ndescription - â¢ HR Payroll Statutory Compliance Performance Management\r\ncompany - \r\ndescription - Employee Relations and Administration: Creating industry specific Policies, Procedure, Forms, Formats, Letters, Checklists etc\r\n\r\nPayroll Management: Salary restructuring to process payroll of 600 employees.\r\nâ¢ Validation of all input (Attendance, Leaves, and Salaries) before starting salary process.\r\nâ¢ Processing accurate & error free salary of employees.\r\nâ¢ Responsible for compensation and benefits administration.\r\nâ¢ Coordinate with Accounts team for salary processing.\r\nâ¢ Attendance & Leave record management\r\nâ¢ Assuring prompt and satisfactory resolution of payroll related queries of all employees.\r\n\r\nStatutory Compliance Management:\r\nâ¢  Manage various statutory compliance requirements (PF, ESIC, PT, Gratuity, TDS etc calculations, deduction, payment and return filing.\r\nâ¢ Generate statutory reports like Form 16, Form 24Q. Conducting session with employees on Statutory Policies and procedure, compliance related topics.\r\nâ¢ Shops and Commercial Establishments Act (S&E)\r\nâ¢ The Payment of Gratuity Act 1972\r\nRecruitment and Selection: Handling recruitment like job posting in naukri portal and coordination. Create annual manpower plan and budget. Screen and schedule preliminary interview. Arrange for employee orientation. Handling joining formalities and salary account opening formalities.\r\n\r\nPerformance Management: End to end facilitation of PMS starting from creating Job Description & Appraisal Forms to Disbursement of Letters. KRA setting, Mid-year reviews, Annual reviews, handling all appraisal activities (360 Degree)\r\n\r\nTraining and Development: Conduct training need analysis and arrange various training session.\r\n\r\nEmployee engagement and  Employee Welfare: Creation and deployment  of Sales  Rewards and Recognition Schemes, Periodic Interactive sessions like Monthly Birthday Celebration, Annual Day, Diwali Dhamaka, Offsite etc.\r\nWorking on Saral Payment Package- payroll software as well as on excel\r\nAssisting MD in HR works, offering suggestions and answering employee queries on payroll compliance related issues, other benefits (insurance, medical, reimbursement, ), full & final settlement of resigned employees."
        ],
        [
         "42",
         "HR",
         "Education Details \r\n BA   mumbai University\r\nHR \r\n\r\n\r\nSkill Details \r\nHr Operations- Exprience - Less than 1 year monthsCompany Details \r\ncompany - Mumbai Monorail\r\ndescription - "
        ],
        [
         "43",
         "HR",
         "Education Details \r\nJune 2012 to May 2015 B.A Economics Chennai, Tamil Nadu Sdnbvc\r\nHr \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - Anything IT Solution\r\ndescription - Hr"
        ],
        [
         "44",
         "HR",
         "Education Details \r\nJune 2012 to May 2015 B.A Economics Chennai, Tamil Nadu Sdnbvc\r\nHr \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - Anything IT Solution\r\ndescription - Hr"
        ],
        [
         "45",
         "HR",
         "Education Details \r\n BBA   lovely professional university\r\nHR \r\n\r\n\r\nSkill Details \r\nCommunication- Exprience - 6 monthsCompany Details \r\ncompany - \r\ndescription - "
        ],
        [
         "46",
         "HR",
         "Education Details \r\n MBA   ACN College of engineering & mgt\r\nHR \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - HR Assistant\r\ndescription - "
        ],
        [
         "47",
         "HR",
         "KEY SKILLS: â¢ Computerized accounting with tally â¢ Sincere & hard working â¢ Management accounting & income tax â¢ Good communication & leadership â¢ Two and four wheeler driving license â¢ Internet & Ecommerce management COMPUTER SKILLS: â¢ C Language â¢ Web programing â¢ Tally â¢ Dbms Education Details \r\nJune 2017 to June 2019 Mba Finance/hr India Mlrit\r\nJune 2014 to June 2017 Bcom Computer Hyderabad, Telangana Osmania university\r\nJune 2012 to April 2014 Inter MEC India Srimedhav\r\nHr \r\n\r\nNani\r\nSkill Details \r\naccounting- Exprience - 6 months\r\nDATABASE MANAGEMENT SYSTEM- Exprience - 6 months\r\nDbms- Exprience - 6 months\r\nManagement accounting- Exprience - 6 months\r\nEcommerce- Exprience - 6 monthsCompany Details \r\ncompany - Valuelabs\r\ndescription - They will give the RRF form the required DLT then the hand over to RLT then scrum master will take the form from the RLT then scrum master will give the forms to trainee which we can work on the requirement till the candidate receive the offer from the company"
        ],
        [
         "48",
         "HR",
         "Training in Special Education (Certificate Course) Education Details \r\nJuly 2016 to October 2018 M.Sc Psychology with specialization in Organizational Behaviour Malappuram, Kerala Calicut University\r\nJuly 2013 to March 2016 BSc Psychology Thrissur Prajyoti Niketan College\r\nHR \r\n\r\n\r\nSkill Details \r\nCompany Details \r\ncompany - \r\ndescription - I have done a 30 days internship in the HR department of Foster Hot Breads, KINFRA, Malappuram, Kerala and I have also done a 60 days internship at Santhwana Institute of Counselling and Psychotherapy, Cochin, Kerala as Counsellor"
        ],
        [
         "49",
         "HR",
         "Computer Knowledge: â¢ Proficient in basic use of MS office â¢ Microsoft Dynamics AX software â¢ SAIBA softwareEducation Details \r\n MBA   Distance education Bharathiar University\r\n BE   PA College of Engineering and Technology\r\n HSC   R.V.G. Hr Sec School\r\n SSC   G.Hr.Sec School\r\nHR \r\n\r\nAdmin in Bharat\r\nSkill Details \r\nDYNAMICS- Exprience - 6 months\r\nDYNAMICS AX- Exprience - 6 months\r\nMICROSOFT DYNAMICS- Exprience - 6 months\r\nMICROSOFT DYNAMICS AX- Exprience - 6 months\r\nMS OFFICE- Exprience - 6 monthsCompany Details \r\ncompany - Sri Ramesh Gaarment\r\ndescription - Tirupur\r\n\r\nAdministration as well as clients service\r\nHere corporate companies only insured so that knowledge gathered about\r\nGarments, spinning mills\r\n\r\nâ¢ FEB 2018 to Still: Sri Ramesh Gaarment Tirupur.\r\n\r\nHR Activities\r\nAttendance maintenance, Time cards maintenance,\r\nStaffs and labors individual records maintenance\r\n\r\nProject:\r\nâ¢ Advanced automobile collision avoidance and blackbox in CAR"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 962
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cb9c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Category                                             Resume\n",
      "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
      "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
      "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
      "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
      "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
      "5  Data Science  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...\n",
      "6  Data Science  Skills â¢ Python â¢ Tableau â¢ Data Visuali...\n",
      "7  Data Science  Education Details \\r\\n B.Tech   Rayat and Bahr...\n",
      "8  Data Science  Personal Skills â¢ Ability to quickly grasp t...\n",
      "9  Data Science  Expertise â Data and Quantitative Analysis â...\n"
     ]
    }
   ],
   "source": [
    "# LLM generated batch iterator\n",
    "# using batches for less requests\n",
    "resumes_df_small = resumes_df.sample(n=100, random_state=42)\n",
    "\n",
    "def batch_iterator(df, batch_size):\n",
    "    \"\"\"Yield batches of rows from a DataFrame.\"\"\"\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        yield df.iloc[start:start + batch_size]\n",
    "\n",
    "# # Example usage:\n",
    "batch_size = 10\n",
    "for batch in batch_iterator(resumes_df, batch_size):\n",
    "    # Process each batch (e.g., send to LLM, print, etc.)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8511eb",
   "metadata": {},
   "source": [
    "### Solve the task using:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eac84d",
   "metadata": {},
   "source": [
    "### 1. Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965dbc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #1\n",
      "Batch #2\n",
      "Batch #2\n",
      "Batch #3\n",
      "Batch #3\n",
      "Batch #4\n",
      "Batch #4\n",
      "Batch #5\n",
      "Batch #5\n",
      "Batch #6\n",
      "Batch #6\n",
      "Batch #7\n",
      "Batch #7\n",
      "Batch #8\n",
      "Batch #8\n",
      "Batch #9\n",
      "Batch #9\n",
      "Batch #10\n",
      "Batch #10\n",
      "Batch #11\n",
      "Batch #11\n",
      "Batch #12\n",
      "Batch #12\n",
      "Batch #13\n",
      "Batch #13\n",
      "Batch #14\n",
      "Batch #14\n",
      "Batch #15\n",
      "Batch #15\n",
      "Batch #16\n",
      "Batch #16\n",
      "Batch #17\n",
      "Batch #17\n",
      "Batch #18\n",
      "Batch #18\n",
      "Batch #19\n",
      "Batch #19\n",
      "Batch #20\n",
      "Batch #20\n",
      "Batch #21\n",
      "Batch #21\n",
      "Batch #22\n",
      "Batch #22\n",
      "Batch #23\n",
      "Batch #23\n",
      "Batch #24\n",
      "Batch #24\n",
      "Batch #25\n",
      "Batch #25\n"
     ]
    }
   ],
   "source": [
    "zeroshot_system_prompt = \"\"\"\n",
    "    You are a master data analyst and annotator, especially skilled in creating JSON objects from rows of a dataframe.\n",
    "    YOu will be provided a dataframe batch, and your job is to convert them into JSON objects for each row.\n",
    "    Only Categories: \"candidate_name\", \"candidate_skills\", \"candidate_experience\", \"candidate_profession\"\n",
    "\"\"\"\n",
    "\n",
    "zeroshot_user_prompt = \"\"\"\n",
    "Convert these rows into JSON:\n",
    "\n",
    "{batch}\n",
    "\n",
    "\"\"\"\n",
    "zero_shot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", zeroshot_system_prompt),\n",
    "    (\"user\", zeroshot_user_prompt),\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "zeroshot_chain = zero_shot_prompt_template | llm | json_parser\n",
    "\n",
    "zeroshot_jsons = []\n",
    "\n",
    "batch_size = 4\n",
    "for i, batch in enumerate(batch_iterator(resumes_df_small, batch_size)):\n",
    "    print(f\"Batch #{i+1}\")\n",
    "    batch_text = \"\\n---\\n\".join(batch['Resume'].astype(str).tolist())\n",
    "    message = zeroshot_chain.invoke({\"batch\": batch_text})\n",
    "    zeroshot_jsons.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88021dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'Servlet',\n",
       "    'JSP',\n",
       "    'Spring Boot',\n",
       "    'HTML5',\n",
       "    'CSS3',\n",
       "    'Bootstrap',\n",
       "    'JavaScript',\n",
       "    'JQuery',\n",
       "    'Ajax',\n",
       "    'AngularJs',\n",
       "    'MySQL',\n",
       "    'Eclipse',\n",
       "    'Spring Tool Suit',\n",
       "    'Net beans',\n",
       "    'Sublime Text',\n",
       "    'Atom',\n",
       "    'Windows XP',\n",
       "    'Windows 7',\n",
       "    'Windows 8',\n",
       "    'Windows 10',\n",
       "    'Spring',\n",
       "    'Hibernate',\n",
       "    'KendoUI',\n",
       "    'Core Java'],\n",
       "   'candidate_experience': ['Css: Less than 1 year',\n",
       "    'Ajax: Less than 1 year',\n",
       "    'Servlet: Less than 1 year',\n",
       "    'Html5: Less than 1 year',\n",
       "    'Spring: Less than 1 year',\n",
       "    'Java: Less than 1 year',\n",
       "    'Jquery: Less than 1 year',\n",
       "    'Jsp: Less than 1 year',\n",
       "    'Javascript: Less than 1 year',\n",
       "    'Bootstrap: Less than 1 year',\n",
       "    'Spring Boot: Less than 1 year',\n",
       "    'Java developer at Salcluster technologies',\n",
       "    'OmegaSoft Technologies pvt.ltd: 5 months',\n",
       "    'Internship Project (Employment Times): 4 months',\n",
       "    'Project (GST And Sales Billing Softwares): 1.5 months',\n",
       "    'Project (Dinman News website): 1 month',\n",
       "    'Project (Agri Management Website): 1.5 months'],\n",
       "   'candidate_profession': ['Java developer', 'Full Stack Java Developer']},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['SpringMVC',\n",
       "    'Hibernate',\n",
       "    'JDBC',\n",
       "    'Java',\n",
       "    'J2EE',\n",
       "    'Azure Web Services',\n",
       "    'JSP',\n",
       "    'Struts',\n",
       "    'Servlet',\n",
       "    'RestApi',\n",
       "    'JavaScript',\n",
       "    'AJAX',\n",
       "    'HTML',\n",
       "    'JSON',\n",
       "    'PHP',\n",
       "    'MsSQL',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Apache Tomcat Server',\n",
       "    'Onesignal Web Push Notifications',\n",
       "    'IONIC',\n",
       "    'Windows Server 2012 R2',\n",
       "    'Windows XP',\n",
       "    'Windows 7',\n",
       "    'Windows 8.1',\n",
       "    'Windows 10',\n",
       "    'Linux',\n",
       "    'Mac OS',\n",
       "    'Ionic 3',\n",
       "    'Angular JS'],\n",
       "   'candidate_experience': ['AJAX: 12 months',\n",
       "    'DATABASE: 24 months',\n",
       "    'HTML: 24 months',\n",
       "    'J2EE: 6 months',\n",
       "    'JAVA: 24 months',\n",
       "    'Spring MVC: 12 months',\n",
       "    'Ionic 3: 6 months',\n",
       "    'Angular JS: 6 months',\n",
       "    'Spring: Less than 1 year',\n",
       "    'Java: Less than 1 year',\n",
       "    'Currently working as Java developer at Replete business solutions pvt ltd'],\n",
       "   'candidate_profession': ['Java developer', 'Java Developer']},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Android',\n",
       "    'Mobile App Development',\n",
       "    'Core Java',\n",
       "    'Advance Java',\n",
       "    'JSF',\n",
       "    'Hibernate',\n",
       "    'Spring',\n",
       "    'C',\n",
       "    'C++',\n",
       "    'Java',\n",
       "    'MS Access',\n",
       "    'SQL',\n",
       "    'Oracle',\n",
       "    'Object Oriented Programming',\n",
       "    'Database',\n",
       "    'PPS',\n",
       "    'AD',\n",
       "    'IAS'],\n",
       "   'candidate_experience': ['Currently working as Java Developer at Infrasoft Technologies',\n",
       "    'Courses done at NIIT: 2015-16',\n",
       "    'Android Project: Location Detector of Computing and Mobile Devices',\n",
       "    'ME Project: Data Deduplication',\n",
       "    'National Conference paper presented: 2011'],\n",
       "   'candidate_profession': ['Java Developer',\n",
       "    'Java Developer - Maxgen Technologies']},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Hadoop',\n",
       "    'Map Reduce',\n",
       "    'HDFS',\n",
       "    'Hive',\n",
       "    'Sqoop',\n",
       "    'Java',\n",
       "    'Core Java',\n",
       "    'Scala',\n",
       "    'Spark',\n",
       "    'Hbase',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Shell Scripting',\n",
       "    'Eclipse',\n",
       "    'Linux',\n",
       "    'CentOS',\n",
       "    'Windows',\n",
       "    'Git',\n",
       "    'Github'],\n",
       "   'candidate_experience': ['Hadoop Developer at Rplus: 2016 to 2017',\n",
       "    'APACHE HADOOP HDFS: 49 months',\n",
       "    'APACHE HADOOP SQOOP: 49 months',\n",
       "    'Hadoop: 49 months',\n",
       "    'HADOOP DISTRIBUTED FILE SYSTEM: 49 months',\n",
       "    'Working at Braindatawire'],\n",
       "   'candidate_profession': ['Hadoop Developer',\n",
       "    'Hadoop Developer - Braindatawire']}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Personal fitness trainer level3',\n",
       "    'Fitness',\n",
       "    'American College of Sports Science certification',\n",
       "    'Golds Gym Heart Saver certification',\n",
       "    'REPS Level 3 certification'],\n",
       "   'candidate_experience': [{'company': 'Golds gym',\n",
       "     'description': 'Certification: American College of Sports Science, Golds Gym Heart Saver, REPS Level 3'},\n",
       "    {'company': 'fitness solution', 'description': None},\n",
       "    {'company': 'flora hotel', 'description': None}],\n",
       "   'candidate_profession': 'personal trainer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Cisco ASA',\n",
       "    'Checkpoint firewall (GAIA, Splat)',\n",
       "    'Palo Alto firewalls',\n",
       "    'Cisco security management (CSM)',\n",
       "    'Checkpoint Smart center',\n",
       "    'Palo Alto Panorama',\n",
       "    'F5 load balancer (LTM)',\n",
       "    'Cisco Router',\n",
       "    'Cisco Switches',\n",
       "    'RSAEnvision 4.1',\n",
       "    'BMC Remedy',\n",
       "    'Service-now',\n",
       "    'Python',\n",
       "    'VB Scripting',\n",
       "    'FIREWALLS (97 months)',\n",
       "    'CISCO (89 months)',\n",
       "    'SECURITY (72 months)',\n",
       "    'FIREWALL (45 months)',\n",
       "    'CHECKPOINT (44 months)',\n",
       "    'F5 LTM configuration',\n",
       "    'SSL offloading',\n",
       "    'Certificate renewals',\n",
       "    'Code upgrade',\n",
       "    'Pulse secure (Juniper) management',\n",
       "    'PAC file configuration',\n",
       "    'Design documents (HLD, LLD)',\n",
       "    'IP Schema',\n",
       "    'Configuration of network devices',\n",
       "    'Incident Management',\n",
       "    'Change management',\n",
       "    'Problem Management (ITIL process)',\n",
       "    'Firewall policy lockdown',\n",
       "    'Software code upgrade',\n",
       "    'Troubleshoot firewalls',\n",
       "    'Cisco Meraki AP',\n",
       "    'Meraki Cloud',\n",
       "    'LAN/WAN monitoring and troubleshooting',\n",
       "    'Vendor interfacing',\n",
       "    'Event monitoring',\n",
       "    'SIEM administration',\n",
       "    'Traffic pattern research',\n",
       "    'IDS/IPS/Scanners (Qualis) analysis',\n",
       "    'Correlation rules',\n",
       "    'Parsers',\n",
       "    'UDS development',\n",
       "    'Security event analysis',\n",
       "    'Change Configuration Management',\n",
       "    'Multi-vendor Network Infrastructure management (Cisco, Juniper)',\n",
       "    'RSA and Entrust (2FA) User Accounts provisioning and troubleshooting',\n",
       "    'Network and security device configuration backup'],\n",
       "   'candidate_experience': [{'company': 'Accenture',\n",
       "     'description': 'Install, configure, upgrades and troubleshoot Cisco ASA firewalls (5500-X), F5 LTM configuration (VIP, pools), SSL offloading, certificate renewals, Code upgrade and troubleshoot issues. Pulse secure (Juniper) management. PAC file configuration. Preparing design documents (HLD, LLD), IP Schema and Configuration of all network devices. Incident Management, Change management, Problem Management (ITIL process). Worked on resiliency project like firewall policy lockdown. Software code upgrade on all firewalls and load balancers. Tools: Cisco security manager 4.x.'},\n",
       "    {'company': 'Zensar Technologies',\n",
       "     'description': \"Install, Upgrades Checkpoint firewalls GAIA R75, R77 and policy deployment. Troubleshoot checkpoint firewalls, Palo alto firewall and Cisco ASA's. Configure, upgrades, troubleshoot Cisco Routers (Cisco 29xx, 28xx, 19xx) and Cisco switches (2960, 3560) and Cisco Meraki AP in Meraki Cloud. F5 LTM configuration and troubleshooting operational issues.\"},\n",
       "    {'company': 'Infosys Technologies',\n",
       "     'description': 'Install, configure, upgrade and troubleshoot checkpoint firewalls, Cisco Routers, Switches. Configure, monitor and troubleshoot issues within organization LAN, WAN and customer Connectivity networks. Interface with vendors and service providers.'},\n",
       "    {'company': 'HCL-Comnet',\n",
       "     'description': 'Event monitoring and administration of RSA enVision 4.1 SIEM. Proficient in researching traffic patterns to identify false-positives and/or malicious traffic within IDS, IPS, scanners (Qualis) and firewalls. Experience in writing correlation rules, parsers & developing UDS for unsupported device logs. Analyze a large volume of security events. Change Configuration Management exposure.'},\n",
       "    {'company': 'Wipro Technologies',\n",
       "     'description': 'Administrator, Manage and troubleshoot multi-vendor Network Infrastructure consisting of Cisco, Juniper Platforms (Cisco Router 3845, Cisco stack-wise switches 3750E and 2960 access switch, Cisco 4500 chassis, Cisco 5550/20 ASA firewalls, Juniper SA 6500 SSL VPN). Provisioning and troubleshooting access issues related to RSA and Entrust (2FA) User Accounts. Taking all network and security devices configuration back up on weekly and monthly basis.'}],\n",
       "   'candidate_profession': 'Senior Network security Analyst'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Microsoft Office (Word, Excel)',\n",
       "    'AutoCAD',\n",
       "    'MicroStation J',\n",
       "    'ERP 3D Modeling software (120 months)',\n",
       "    'Application Engineering',\n",
       "    'Pre Sales & Inside Sales',\n",
       "    'Product selection',\n",
       "    'Materials of construction technical recommendations',\n",
       "    'Field Service',\n",
       "    'Project quotation (technical part)',\n",
       "    'Sizing and costing of Pneumatic Automation Products, valves, linear & rotary actuator, field Fabrication & equipment',\n",
       "    'Customer specification review',\n",
       "    'Techno-commercial quotations',\n",
       "    'Coordination with technical departments',\n",
       "    'Quotation submission and follow-up',\n",
       "    'Payment collection',\n",
       "    'PO review and amendment',\n",
       "    'Order transfer file creation',\n",
       "    'Post-order activities & after-sales service',\n",
       "    'Proposal/Estimation Engineering',\n",
       "    'Products Costing',\n",
       "    'RFQ review',\n",
       "    \"Estimation of Pneumatic Automation Products & Projects, valves, linear & rotary actuator, field equipment, Piping, Fabricated equipment's\",\n",
       "    'Vendor inquiries and follow-up',\n",
       "    'Design thumb rules/standard practices',\n",
       "    'Cost analysis (estimated vs. actual)',\n",
       "    'Quotation databank maintenance',\n",
       "    'Coordination with Instrumentation & Electrical departments',\n",
       "    'Site visits for projects',\n",
       "    'Vendor development',\n",
       "    'Client requirement analysis',\n",
       "    'Chemtronics solution offering',\n",
       "    'Work assignment to Jr. Proposal executives/Engineers',\n",
       "    'Coordination with design, CAD, sales, marketing, project & commercial departments',\n",
       "    'Engineering Procurement & Purchase',\n",
       "    'Vendor Development & Supply Chain',\n",
       "    'Procurement of Steel/Raw Material & semi-finish Products',\n",
       "    'Negotiation process improvement',\n",
       "    'Cost saving opportunities',\n",
       "    'Turnaround time improvement',\n",
       "    'Contract Management & Tenders',\n",
       "    'Target savings achievement',\n",
       "    'Vendor research and evaluation',\n",
       "    'Technical comparison of prices',\n",
       "    'Vendor relationship management',\n",
       "    'Quality inspection of products/supplies',\n",
       "    'Digitize procurement processes',\n",
       "    'Track purchasing plans, inventory, delivery',\n",
       "    'Database management (suppliers, invoices)',\n",
       "    'Collaboration with financial team',\n",
       "    'RFQ creation for materials/services',\n",
       "    'Vendor evaluation & registration',\n",
       "    'Project execution',\n",
       "    'Supply chain Management',\n",
       "    'Customer process understanding',\n",
       "    'Solution development',\n",
       "    'Lead proposal engineering team',\n",
       "    'Technical support to customer',\n",
       "    'Sales team collaboration',\n",
       "    'Data gathering and project definition',\n",
       "    'Cost estimation',\n",
       "    'Production process identification',\n",
       "    'Critical problem identification and resolution',\n",
       "    'Production design (new manufacturing process, new product development)',\n",
       "    'Customized manufacturing solutions (Steel, Power & Cement, petrochemical sector)',\n",
       "    'Cost saving techniques/measures',\n",
       "    'O&M expenditures reduction',\n",
       "    'Budget management',\n",
       "    'Customer relationship management',\n",
       "    'Technical data sheets preparation',\n",
       "    'Price structure calculation and cost proposal analysis',\n",
       "    'Progress monitoring',\n",
       "    'Mechanical assemblies design/modification',\n",
       "    'Hydraulic/pneumatic assemblies design/modification',\n",
       "    'Fabricated assembly design/modification',\n",
       "    'Layouts/schematics and detailed drawings',\n",
       "    'Electrical/mechanical product specifications generation',\n",
       "    'Standard operating procedures',\n",
       "    'Maintenance manuals',\n",
       "    'Basic mechanical design',\n",
       "    'Innovative solutions development',\n",
       "    'Engineering test reports & analysis',\n",
       "    'Manufacturing process adherence (ISO9001-2015)',\n",
       "    'Non-Conformity (NC) records management',\n",
       "    'Obsolete documents management',\n",
       "    'ISO document maintenance and awareness',\n",
       "    'Internal audit execution',\n",
       "    'Controlled drawings record maintenance',\n",
       "    'Coordination with channel partners, OEMs, dealers, consultants, end customers',\n",
       "    'Drawing detailing',\n",
       "    'BOM preparation',\n",
       "    'Raw material inspection',\n",
       "    'Prototype manufacturing (3D modeling)',\n",
       "    'Gauge preparation for inspection',\n",
       "    'Marking on housing for machining',\n",
       "    'Surface finishing checking'],\n",
       "   'candidate_experience': [{'company': 'Mechanical Engineering',\n",
       "     'description': 'Role & Responsibilities: Application Engineering / Pre Sales & Inside Sales, Proposal/Estimation Engineering & Products Costing, Engg. Procurement & Purchase, Vendor Development & Supply Chain.'},\n",
       "    {'company': 'M/s Duncan Engineering Ltd, Pune',\n",
       "     'description': 'Project execution, Vendor development, supply chain Management, interacting with Vendors to ensure timely action of order & negotiating with the vendor. Work directly with customer to understand their process and develop the best solution. Lead proposal engineering team & technical support to customer. Work with sales team to professionally represent the company, gather Data and ask the right question to define a project. Work with engineers and designer to develop and quote cost effective solution. Cost estimation, preparing proposal & quotation base on Technical specification of Customer requirement & identify production process and machines/bought out Item requirements. Co-ordinate with customer to understand exact requirements. Identification of critical problem & work out Proper solution. Production design-new manufacturing process - new product development. Developing Customized manufacturing solutions. Executing cost saving techniques/ measures and modifications to achieve Substantial Reduction in O & M expenditures and work within the budget. Maintaining fruitful Relationships with existing customers.'},\n",
       "    {'company': 'Rotex Engineers & Manufacturing Pvt. Ltd',\n",
       "     'description': 'Manage & enhance the activity related to proposal of pneumatics/fabrication projects & products. Project execution, Vendor development, supply chain Management, interacting with vendors to ensure Timely action of order & Negotiating with the vendor. Production design-new manufacturing process - new product development. Developing Customized manufacturing solutions. Preparation of technical data sheets as per tender specification. Calculate price structure and analyze cost proposals. Monitoring progress throughout the job & comparing it with the schedule of work. Maintaining fruitful relationships with existing customers. Review Vendor evaluation & Vendor registration from Supply time & quality of products. Examine and review products and supplies to ensure quality.'},\n",
       "    {'company': 'M/s Schrader Duncan Ltd, Pune',\n",
       "     'description': 'Project execution, Vendor development, supply chain Management, interacting with Vendors to ensure timely action of order & negotiating with the vendor. Design or modify Mechanical assemblies, hydraulic/pneumatic assemblies, Fabricated assy Along with layouts/schematics and/or detailed drawings as per specification. Generate electrical or mechanical product specifications, standard operating procedures, maintenance manuals & Doing basic mechanical design. Participate in growth & developing innovative solutions with design & development, sales & marketing team. Define, coordinate, perform and generate engineering test reports & engineering analysis. In Co-Ordination with production manager implement and assure that all manufacturing processes are being followed. Maintain records of Non-Conformity (NC) and close the same with corrective actions. Maintain records of obsolete documents and remain in touch with all HODs. Maintain ISO documents pertaining to ISO9001-2015 and bring awareness among employees. Carry Out internal audit and maintain the record of controlled drawings. Coordinate & communicate with channel partners, O.E.M.s, dealers, consultants & end customers for Design & offer technically feasible.'},\n",
       "    {'company': 'JOIST- O- MECH Engg. Pvt. Ltd',\n",
       "     'description': 'Detailing of drawing, Preparations of BOM & raw material inspection. Prototype manufacturing (3d modeling).'},\n",
       "    {'company': 'MUKAND LTD, Kurla',\n",
       "     'description': 'Raw material inspection, Preparations of Gauge for inspection, marking on housing for machining, checking surface finishing.'}],\n",
       "   'candidate_profession': 'Sr. Executive-Mechanical Engineering- Automation & Projects Consultant'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Manual Testing',\n",
       "    'Automation Testing',\n",
       "    'SELENIUM IDE',\n",
       "    'TestNG',\n",
       "    'SELENIUM Grid',\n",
       "    'JENKINS',\n",
       "    'Apache POI',\n",
       "    'SDLC',\n",
       "    'White Box Testing',\n",
       "    'Black Box Testing',\n",
       "    'Functional Testing',\n",
       "    'Integration Testing',\n",
       "    'System Testing',\n",
       "    'Writing Functional and Integration Scenarios',\n",
       "    'Test case design technique',\n",
       "    'Build and release',\n",
       "    'Ad hoc testing',\n",
       "    'Smoke testing',\n",
       "    'Usability testing',\n",
       "    'Reliability testing',\n",
       "    'Exploratory testing',\n",
       "    'Globalization testing',\n",
       "    'Compatibility Testing',\n",
       "    'STLC',\n",
       "    'Regression testing',\n",
       "    'Retesting',\n",
       "    'Defect tracking',\n",
       "    'Defect Life Cycle',\n",
       "    'Test plan',\n",
       "    'Traceability Matrix',\n",
       "    'Jdbc',\n",
       "    'Servlets',\n",
       "    'Jsp',\n",
       "    'Web based Application',\n",
       "    'MS Access2007',\n",
       "    'Resume Extractor (project skill)',\n",
       "    'Teamwork',\n",
       "    'System and Operational Analysis',\n",
       "    'Communication Skills',\n",
       "    'Active learning',\n",
       "    'Critical thinking',\n",
       "    'Interpersonal skills',\n",
       "    'Adaptability to new technologies',\n",
       "    'APACHE (6 months)',\n",
       "    'BLACK BOX (6 months)',\n",
       "    'BLACK BOX TESTING (6 months)',\n",
       "    'FUNCTIONAL TESTING (6 months)',\n",
       "    'INTEGRATION (6 months)'],\n",
       "   'candidate_experience': [{'company': 'Tech Mahindra',\n",
       "     'description': 'Software testing in manual and Automation.'},\n",
       "    {'company': None, 'description': 'Software Test Engineer.'},\n",
       "    {'company': 'Source-Code Technology, Pune (Corporate Training)',\n",
       "     'description': \"Completed 'CORPORATE TRAINING in Manual and Automation Testing'.\"},\n",
       "    {'company': None,\n",
       "     'description': 'Internship Project: Resume Extractor (6 months) - Manual And Automation Testing in Jdbc, Servlets, Jsp, Web based Application, MS Access2007.'}],\n",
       "   'candidate_profession': 'Software testing'}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_jsons[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725aa61",
   "metadata": {},
   "source": [
    "### 2. One-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea90880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RESUME_PATH = \"datasets/part1/task1/resumes/resume1.txt\"\n",
    "SAMPLE_RESUME_2_PATH = \"datasets/part1/task1/resumes/resume2.txt\"\n",
    "SAMPLE_RESUME_3_PATH = \"datasets/part1/task1/resumes/resume3.txt\"\n",
    "SAMPLE_JSON_PATH = \"datasets/part1/task1/resume_outputs.json\"\n",
    "\n",
    "sample_resume = None\n",
    "sample_json = None\n",
    "\n",
    "with open(SAMPLE_RESUME_PATH, \"r\") as file:\n",
    "    sample_resume = file.read()\n",
    "\n",
    "with open(SAMPLE_JSON_PATH, \"r\") as f:\n",
    "    sample_json = json.load(f)['resume1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Resume 1: Senior Software Engineer**\\n\\n**Alex Chen**\\nSan Francisco, CA | (123) 456-7890 | alex.chen@email.com | linkedin.com/in/alexchen\\n\\n**Summary**\\nA seasoned Senior Software Engineer with over 10 years of experience in designing, developing, and scaling high-performance web applications. Proven ability to lead technical projects, mentor junior engineers, and drive the adoption of modern software architecture and DevOps practices. Deep expertise in the JavaScript/TypeScript ecosystem and cloud platforms.\\n\\n**Professional Experience**\\n\\n*Senior Software Engineer*, TechFlow Inc., San Francisco, CA | 2018 – Present\\n*   Led the redesign of a monolithic payment processing service into a microservices architecture, improving system uptime from 99.9% to 99.99% and reducing latency by 40%.\\n*   Architected and implemented a real-time data dashboard using React, Node.js, and WebSockets, serving over 1 million daily active users.\\n*   Mentored 4 junior and mid-level engineers, conducting code reviews and facilitating their technical growth.\\n*   Spearheaded the adoption of TypeScript across the front-end codebase, reducing runtime errors by 60%.\\n*   Implemented comprehensive CI/CD pipelines using Docker, Jenkins, and Kubernetes, decreasing deployment times by 70%.\\n\\n*Software Engineer*, Innovate Solutions, Austin, TX | 2014 – 2018\\n*   Developed and maintained customer-facing features for a large-scale SaaS product using AngularJS and Java/Spring Boot.\\n*   Collaborated with product managers and designers in an Agile environment to deliver user stories on schedule.\\n*   Wrote unit and integration tests, achieving 90% code coverage and improving overall code quality.\\n\\n**Skills**\\n*   **Programming Languages:** JavaScript (Expert), TypeScript (Expert), Python (Proficient), Java (Proficient)\\n*   **Frameworks & Libraries:** React, Node.js, Express.js, Next.js, Spring Boot\\n*   **Databases:** PostgreSQL, MongoDB, Redis\\n*   **Tools & Platforms:** Docker, Kubernetes, AWS (EC2, S3, RDS, Lambda), Jenkins, Git, JIRA\\n\\n**Education**\\nBachelor of Science in Computer Science | University of Texas at Austin | 2014'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0e29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate_name': 'Alex Chen',\n",
       " 'candidate_skills': ['JavaScript',\n",
       "  'TypeScript',\n",
       "  'React',\n",
       "  'Node.js',\n",
       "  'Microservices',\n",
       "  'AWS',\n",
       "  'Docker',\n",
       "  'Kubernetes',\n",
       "  'CI/CD',\n",
       "  'System Architecture',\n",
       "  'Mentoring'],\n",
       " 'candidate_experience': 10,\n",
       " 'candidate_profession': 'Senior Software Engineer'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #1\n",
      "Batch #2\n",
      "Batch #3\n",
      "Batch #4\n",
      "Batch #5\n",
      "Batch #6\n",
      "Batch #7\n",
      "Batch #8\n",
      "Batch #9\n",
      "Batch #10\n",
      "Batch #11\n",
      "Batch #12\n",
      "Batch #13\n",
      "Batch #14\n",
      "Batch #15\n",
      "Batch #16\n",
      "Batch #17\n",
      "Batch #18\n",
      "Batch #19\n",
      "Batch #20\n",
      "Batch #21\n",
      "Batch #22\n",
      "Batch #23\n",
      "Batch #24\n",
      "Batch #25\n"
     ]
    }
   ],
   "source": [
    "oneshot_system_prompt = \"\"\" \n",
    "    You are a master data analyst and annotator, especially skilled in creating JSON objects from rows of a dataframe.\n",
    "    You will be provided a dataframe batch, and your job is to convert them into JSON objects for each row.\n",
    "    Only Categories: \"candidate_name\", \"candidate_skills\", \"candidate_experience\", \"candidate_profession\"\n",
    "\"\"\"\n",
    "\n",
    "oneshot_user_prompt = \"\"\"\n",
    "    Given a row of data, your job is to convert this row into a JSON object. Analyse the following example for reference...\n",
    "    \n",
    "    Sample row:\n",
    "    {sample_row}\n",
    "    \n",
    "    Sample JSON:\n",
    "    {sample_json}\n",
    "    \n",
    "    Now, convert these rows into JSON:\n",
    "    {batch}\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "oneshot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", oneshot_system_prompt),\n",
    "    (\"user\", oneshot_user_prompt),\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "oneshot_chain = oneshot_prompt_template | llm | json_parser\n",
    "\n",
    "oneshot_jsons = []\n",
    "\n",
    "batch_size = 4\n",
    "for i, batch in enumerate(batch_iterator(resumes_df_small, batch_size)):\n",
    "    print(f\"Batch #{i+1}\")\n",
    "    batch_text = \"\\n---\\n\".join(batch['Resume'].astype(str).tolist())\n",
    "    message = oneshot_chain.invoke(\n",
    "    {\n",
    "        \"sample_row\": sample_resume, \n",
    "        \"sample_json\": sample_json, \n",
    "        \"batch\": batch_text,\n",
    "    })\n",
    "    \n",
    "    oneshot_jsons.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bd55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'Servlet',\n",
       "    'JSP',\n",
       "    'Spring Boot',\n",
       "    'HTML5',\n",
       "    'CSS3',\n",
       "    'Bootstrap',\n",
       "    'JavaScript',\n",
       "    'jQuery',\n",
       "    'Ajax',\n",
       "    'AngularJS',\n",
       "    'MySQL',\n",
       "    'Eclipse',\n",
       "    'Spring Tool Suite',\n",
       "    'NetBeans',\n",
       "    'Sublime Text',\n",
       "    'Atom',\n",
       "    'Spring',\n",
       "    'Hibernate',\n",
       "    'KendoUI',\n",
       "    'MVC Architecture'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Full Stack Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Spring MVC',\n",
       "    'Hibernate',\n",
       "    'JDBC',\n",
       "    'Java',\n",
       "    'J2EE',\n",
       "    'Azure Web Services',\n",
       "    'JSP',\n",
       "    'Struts',\n",
       "    'Servlet',\n",
       "    'REST API',\n",
       "    'JavaScript',\n",
       "    'AJAX',\n",
       "    'HTML',\n",
       "    'JSON',\n",
       "    'PHP',\n",
       "    'MS SQL',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Apache Tomcat',\n",
       "    'OneSignal',\n",
       "    'Ionic',\n",
       "    'AngularJS',\n",
       "    'Linux',\n",
       "    'Mac OS',\n",
       "    'Windows Server'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Android',\n",
       "    'Mobile App Development',\n",
       "    'Java',\n",
       "    'JSF',\n",
       "    'Hibernate',\n",
       "    'Spring',\n",
       "    'C',\n",
       "    'C++',\n",
       "    'Object Oriented Programming',\n",
       "    'MS Access',\n",
       "    'SQL',\n",
       "    'Oracle'],\n",
       "   'candidate_experience': 11,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Hadoop',\n",
       "    'MapReduce',\n",
       "    'HDFS',\n",
       "    'Hive',\n",
       "    'Sqoop',\n",
       "    'Java',\n",
       "    'Scala',\n",
       "    'Spark',\n",
       "    'Hbase',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Shell Scripting',\n",
       "    'Eclipse',\n",
       "    'Linux',\n",
       "    'Windows',\n",
       "    'Git',\n",
       "    'GitHub'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Hadoop Developer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Personal Fitness Trainer',\n",
       "    'Fitness',\n",
       "    'American College of Sports Science',\n",
       "    'Golds Gym Heart Saver',\n",
       "    'REPS Level 3'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Personal trainer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Cisco ASA',\n",
       "    'Checkpoint Firewall',\n",
       "    'Palo Alto Firewalls',\n",
       "    'Firewall Management',\n",
       "    'Cisco Security Management',\n",
       "    'Checkpoint Smart Center',\n",
       "    'Palo Alto Panorama',\n",
       "    'F5 Load Balancer',\n",
       "    'Networking',\n",
       "    'Cisco Router',\n",
       "    'Cisco Switches',\n",
       "    'Security Management',\n",
       "    'Event Management',\n",
       "    'RSAEnvision',\n",
       "    'BMC Remedy',\n",
       "    'Service-Now',\n",
       "    'Python',\n",
       "    'VB Scripting',\n",
       "    'ITIL Process',\n",
       "    'Incident Management',\n",
       "    'Change Management',\n",
       "    'Problem Management',\n",
       "    'SSL Offloading',\n",
       "    'Certificate Renewals',\n",
       "    'Code Upgrade',\n",
       "    'Pulse Secure',\n",
       "    'Juniper',\n",
       "    'PAC File Configuration',\n",
       "    'HLD',\n",
       "    'LLD',\n",
       "    'Network Devices Configuration',\n",
       "    'Data Center Environment',\n",
       "    'Firewall Policy Lockdown',\n",
       "    'Load Balancers',\n",
       "    'Cisco Security Manager',\n",
       "    'GAIA R75',\n",
       "    'GAIA R77',\n",
       "    'Policy Deployment',\n",
       "    'Cisco Meraki AP',\n",
       "    'Meraki Cloud',\n",
       "    'LAN',\n",
       "    'WAN',\n",
       "    'IDS',\n",
       "    'IPS',\n",
       "    'Qualis',\n",
       "    'Correlation Rules',\n",
       "    'Parsers',\n",
       "    'UDS Development',\n",
       "    'SIEM',\n",
       "    'Change Configuration Management',\n",
       "    'SSL VPN',\n",
       "    'RSA',\n",
       "    'Entrust (2FA)',\n",
       "    'Network Infrastructure Administration',\n",
       "    'Configuration Backup'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Senior Network security Analyst'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Microsoft Office',\n",
       "    'Word',\n",
       "    'Excel',\n",
       "    'AutoCAD',\n",
       "    'MicroStation J',\n",
       "    'ERP',\n",
       "    '3D Modeling',\n",
       "    'Application Engineering',\n",
       "    'Pre Sales',\n",
       "    'Inside Sales',\n",
       "    'Product Selection',\n",
       "    'Technical Recommendations',\n",
       "    'Project Management',\n",
       "    'Vendor Development',\n",
       "    'Supply Chain Management',\n",
       "    'Negotiation',\n",
       "    'Cost Estimation',\n",
       "    'Proposal Engineering',\n",
       "    'Production Design',\n",
       "    'New Product Development',\n",
       "    'Manufacturing Solutions',\n",
       "    'Technical Data Sheets',\n",
       "    'Price Structure Analysis',\n",
       "    'Procurement',\n",
       "    'Purchase',\n",
       "    'Contract Management',\n",
       "    'Tenders',\n",
       "    'Design Engineering',\n",
       "    'Mechanical Assemblies',\n",
       "    'Hydraulic Assemblies',\n",
       "    'Pneumatic Assemblies',\n",
       "    'Fabrication',\n",
       "    'Layouts',\n",
       "    'Schematics',\n",
       "    'Detailed Drawings',\n",
       "    'Electrical Product Specifications',\n",
       "    'Mechanical Product Specifications',\n",
       "    'Standard Operating Procedures',\n",
       "    'Maintenance Manuals',\n",
       "    'Engineering Test Reports',\n",
       "    'Engineering Analysis',\n",
       "    'Manufacturing Processes',\n",
       "    'ISO 9001-2015',\n",
       "    'Internal Audit',\n",
       "    'Bill of Materials (BOM)',\n",
       "    'Raw Material Inspection',\n",
       "    'Prototype Manufacturing',\n",
       "    'Gauge Inspection',\n",
       "    'Surface Finishing'],\n",
       "   'candidate_experience': 10,\n",
       "   'candidate_profession': 'Sr. Executive-Mechanical Engineering- Automation & Projects Consultant'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Manual Testing',\n",
       "    'Automation Testing',\n",
       "    'Selenium IDE',\n",
       "    'TestNG',\n",
       "    'Selenium Grid',\n",
       "    'Jenkins',\n",
       "    'Apache POI',\n",
       "    'SDLC',\n",
       "    'White Box Testing',\n",
       "    'Black Box Testing',\n",
       "    'Functional Testing',\n",
       "    'Integration Testing',\n",
       "    'System Testing',\n",
       "    'Test Case Design',\n",
       "    'Build and Release',\n",
       "    'Ad Hoc Testing',\n",
       "    'Smoke Testing',\n",
       "    'Usability Testing',\n",
       "    'Reliability Testing',\n",
       "    'Exploratory Testing',\n",
       "    'Globalization Testing',\n",
       "    'Compatibility Testing',\n",
       "    'STLC',\n",
       "    'Regression Testing',\n",
       "    'Retesting',\n",
       "    'Defect Tracking',\n",
       "    'Defect Life Cycle',\n",
       "    'Test Plan',\n",
       "    'Traceability Matrix',\n",
       "    'JDBC',\n",
       "    'Servlets',\n",
       "    'JSP',\n",
       "    'Web Applications',\n",
       "    'MS Access',\n",
       "    'Apache',\n",
       "    'Teamwork',\n",
       "    'System Analysis',\n",
       "    'Operational Analysis',\n",
       "    'Communication',\n",
       "    'Critical Thinking',\n",
       "    'Interpersonal Skills',\n",
       "    'Learning New Technologies'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Software testing'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Legal'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Advocate'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Windows 10',\n",
       "    'Ms-Office',\n",
       "    'Word',\n",
       "    'Excel',\n",
       "    'PowerPoint',\n",
       "    'Internet',\n",
       "    'Gym Management Software',\n",
       "    'Sales',\n",
       "    'Fitness',\n",
       "    'Operations',\n",
       "    'Administration',\n",
       "    'Facility Management',\n",
       "    'House-keeping',\n",
       "    'Recruitment',\n",
       "    'Marketing',\n",
       "    'Customer Relationship',\n",
       "    'Budgeting',\n",
       "    'Health and Safety',\n",
       "    'Customer Service',\n",
       "    'Planning'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Gym management & Consultant'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'Hadoop',\n",
       "    'HDFS',\n",
       "    'MapReduce',\n",
       "    'Pig',\n",
       "    'Hive',\n",
       "    'Sqoop',\n",
       "    'Flume',\n",
       "    'Oozie',\n",
       "    'HBase',\n",
       "    'Spark',\n",
       "    'Scala',\n",
       "    'Linux',\n",
       "    'NoSQL',\n",
       "    'Storm',\n",
       "    'Tomcat',\n",
       "    'Putty',\n",
       "    'SVN',\n",
       "    'GitHub',\n",
       "    'IBM WebSphere',\n",
       "    'AWS',\n",
       "    'Eclipse IDE',\n",
       "    'Windows',\n",
       "    'Oracle',\n",
       "    'Teradata',\n",
       "    'MySQL',\n",
       "    'TPT',\n",
       "    'Connect Direct',\n",
       "    'Avro',\n",
       "    'Cloudera',\n",
       "    'Shell Scripting',\n",
       "    'Python',\n",
       "    'PL/SQL',\n",
       "    'SQL',\n",
       "    'Data Warehousing',\n",
       "    'Analytics',\n",
       "    'Troubleshooting',\n",
       "    'Optimization',\n",
       "    'Technical Documentation',\n",
       "    'BI Reporting',\n",
       "    'Distributed Processing',\n",
       "    'Cluster Management',\n",
       "    'Security',\n",
       "    'System Performance',\n",
       "    'Data Migration',\n",
       "    'Workflow Orchestration',\n",
       "    'Unit Testing'],\n",
       "   'candidate_experience': 7,\n",
       "   'candidate_profession': 'Hadoop Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Communication'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Microsoft Office',\n",
       "    'AutoCAD',\n",
       "    'Catia',\n",
       "    'Solidworks',\n",
       "    'ERP System',\n",
       "    '3D Modelling',\n",
       "    'ProE',\n",
       "    'Positive Attitude',\n",
       "    'Quick Learner',\n",
       "    'Team Leader'],\n",
       "   'candidate_experience': 5,\n",
       "   'candidate_profession': 'Mechanical Design Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['MS Office',\n",
       "    'Word',\n",
       "    'Excel',\n",
       "    'Powerpoint',\n",
       "    'Windows',\n",
       "    'Internet',\n",
       "    'Hard Working',\n",
       "    'Loyalty',\n",
       "    'Creativity',\n",
       "    'Self-motivated',\n",
       "    'Responsible',\n",
       "    'Initiative',\n",
       "    'People Management',\n",
       "    'Positive Attitude',\n",
       "    'Electrical Testing',\n",
       "    'Circuit Breaker Testing',\n",
       "    'CRM',\n",
       "    'IR Test',\n",
       "    'MCC Panel',\n",
       "    'PCC Panel',\n",
       "    'Transformer Testing',\n",
       "    'Hi-Pot Test',\n",
       "    'Megger',\n",
       "    'Relay Connections',\n",
       "    'Defect Analysis',\n",
       "    'Problem Solving'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Testing Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Ubuntu',\n",
       "    'Fedora',\n",
       "    'CentOS',\n",
       "    'Windows',\n",
       "    'MySQL',\n",
       "    'Python',\n",
       "    'Tensorflow',\n",
       "    'Numpy',\n",
       "    'C',\n",
       "    'C++'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Python Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['AutoCAD',\n",
       "    'MS Office',\n",
       "    'Windows',\n",
       "    'Civil Engineering',\n",
       "    'Drafting',\n",
       "    'Construction Management',\n",
       "    'Excavation',\n",
       "    'Foundation',\n",
       "    'PCC',\n",
       "    'Waterproofing',\n",
       "    'RCC',\n",
       "    'Shuttering',\n",
       "    'Steel Fixing',\n",
       "    'Concrete Casting',\n",
       "    'Masonry',\n",
       "    'Plastering',\n",
       "    'Tile Fixing',\n",
       "    'Design Review',\n",
       "    'Architecture',\n",
       "    'Structural Engineering',\n",
       "    'Site Inspection',\n",
       "    'Procurement',\n",
       "    'Site Supervision',\n",
       "    'Scheduling',\n",
       "    'Bill Verification',\n",
       "    'Quantity Surveying',\n",
       "    'Communication',\n",
       "    'Hardworking',\n",
       "    'Sincerity',\n",
       "    'Honesty',\n",
       "    'Teamwork',\n",
       "    '5M (Manpower, Material, Machine, Management, Methods)',\n",
       "    'Program Strategy'],\n",
       "   'candidate_experience': 7,\n",
       "   'candidate_profession': 'Civil Engineer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Python',\n",
       "    'SQL',\n",
       "    'Java',\n",
       "    'JavaScript',\n",
       "    'Machine Learning',\n",
       "    'Natural Language Processing',\n",
       "    'Deep Learning',\n",
       "    'Tableau',\n",
       "    'ElasticSearch',\n",
       "    'Docker',\n",
       "    'Git',\n",
       "    'Angular',\n",
       "    'Node.js'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Data Science Assurance Associate'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Excel',\n",
       "    'MIS',\n",
       "    'Reporting',\n",
       "    'Data Analysis',\n",
       "    'IT Operations',\n",
       "    'Team Management',\n",
       "    'Cash Management'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Business Analyst'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Talend',\n",
       "    'ETL',\n",
       "    'Informatica PowerCenter',\n",
       "    'SQL Server',\n",
       "    'SQL',\n",
       "    'AWS',\n",
       "    'Data Warehousing',\n",
       "    'Data Modeling',\n",
       "    'Data Integration',\n",
       "    'Agile',\n",
       "    'MySQL',\n",
       "    'DB2'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Talend ETL Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['C#',\n",
       "    'ASP.NET MVC',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'JavaScript',\n",
       "    'AngularJS',\n",
       "    'Entity Framework',\n",
       "    'SQL Server',\n",
       "    'Visual Studio',\n",
       "    '3-tier architecture'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Dot Net Developer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Project Management',\n",
       "    'PMO',\n",
       "    'Risk Management',\n",
       "    'SDLC',\n",
       "    'Data Analysis',\n",
       "    'Reporting',\n",
       "    'Governance',\n",
       "    'Documentation',\n",
       "    'Forecasting',\n",
       "    'Stakeholder Management',\n",
       "    'Leadership',\n",
       "    'Team Handling',\n",
       "    'Quality Analysis',\n",
       "    'MS Office',\n",
       "    'Excel',\n",
       "    'Macros',\n",
       "    'Strategic Thinking',\n",
       "    'Analytical Skills',\n",
       "    'Multitasking'],\n",
       "   'candidate_experience': 6,\n",
       "   'candidate_profession': 'PMO'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Martial Arts',\n",
       "    'Karate',\n",
       "    'Fitness',\n",
       "    'Personal Training'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Personal Trainer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['ETL',\n",
       "    'Informatica',\n",
       "    'Oracle',\n",
       "    'SQL',\n",
       "    'PL/SQL',\n",
       "    'UNIX',\n",
       "    'Facets',\n",
       "    'Tidal',\n",
       "    'JIRA',\n",
       "    'Putty',\n",
       "    'Business Requirements Analysis',\n",
       "    'Data Mapping',\n",
       "    'Debugging',\n",
       "    'Scripting',\n",
       "    'Unit Testing',\n",
       "    'Troubleshooting',\n",
       "    'Design Documentation'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'ETL Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Transformer Testing',\n",
       "    'Quality Control',\n",
       "    'Routine Testing',\n",
       "    'Type Testing',\n",
       "    'Special Testing',\n",
       "    'Power Transformers',\n",
       "    'Distribution Transformers',\n",
       "    'RTCC',\n",
       "    'OLTC',\n",
       "    'Root Cause Analysis',\n",
       "    'CAPA',\n",
       "    'ISO Audit',\n",
       "    'BIS Audit',\n",
       "    'Calibration',\n",
       "    'Documentation',\n",
       "    'On-site Commissioning',\n",
       "    'ERDA Testing',\n",
       "    'Leadership'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Testing and Quality Control Engineer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['MS Office',\n",
       "    'Word',\n",
       "    'Excel',\n",
       "    'Power Point',\n",
       "    'Windows',\n",
       "    'Internet',\n",
       "    'Testing',\n",
       "    'Circuit Breaker',\n",
       "    'CRM',\n",
       "    'IR Test',\n",
       "    'MCC Panel',\n",
       "    'PCC Panel',\n",
       "    'Transformer Testing',\n",
       "    'HV Cables',\n",
       "    'Hi-Pot Test',\n",
       "    'LV Cables',\n",
       "    'Megger',\n",
       "    'Relay Connections',\n",
       "    'Defect Management'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Testing Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['R',\n",
       "    'Python',\n",
       "    'SAP HANA',\n",
       "    'Tableau',\n",
       "    'SAP HANA SQL',\n",
       "    'SAP HANA PAL',\n",
       "    'MS SQL',\n",
       "    'SAP Lumira',\n",
       "    'C#',\n",
       "    'Linear Programming',\n",
       "    'Data Modelling',\n",
       "    'Advanced Analytics',\n",
       "    'SCM Analytics',\n",
       "    'Retail Analytics',\n",
       "    'Social Media Analytics',\n",
       "    'NLP',\n",
       "    'Deep Learning',\n",
       "    'Machine Learning',\n",
       "    'SQL',\n",
       "    'SAP AO',\n",
       "    'BOBJ',\n",
       "    'Time Series Forecasting',\n",
       "    'Anaconda',\n",
       "    'K-means',\n",
       "    'Decision Tree',\n",
       "    'SAP PAL',\n",
       "    'SQL Server',\n",
       "    'Visual Studio',\n",
       "    'Windows Server',\n",
       "    'Performance Monitoring',\n",
       "    'SQL Profiler',\n",
       "    'ETL',\n",
       "    'LSTM Models',\n",
       "    'Object Detection',\n",
       "    'Sentence Creation',\n",
       "    'UML'],\n",
       "   'candidate_experience': 5,\n",
       "   'candidate_profession': 'Data Science Consultant'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['MS-Office',\n",
       "    'Communication',\n",
       "    'Sales',\n",
       "    'Marketing',\n",
       "    'Customer Sales Management',\n",
       "    'Talent Management',\n",
       "    'Direct Sales Management'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Sales manager'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Multi-tasking',\n",
       "    'Collaboration',\n",
       "    'Team Leadership',\n",
       "    'Team Training',\n",
       "    'Communication',\n",
       "    'MS Office',\n",
       "    'Sales',\n",
       "    'Marketing',\n",
       "    'Business Management',\n",
       "    'Lead Generation',\n",
       "    'Cold Calling',\n",
       "    'Client Solutions'],\n",
       "   'candidate_experience': None,\n",
       "   'candidate_profession': 'Sales Manager'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Manual Testing',\n",
       "    'Automation Testing',\n",
       "    'Selenium',\n",
       "    'TestNG',\n",
       "    'Jenkins',\n",
       "    'Apache POI',\n",
       "    'SDLC',\n",
       "    'STLC',\n",
       "    'Black Box Testing',\n",
       "    'White Box Testing',\n",
       "    'Functional Testing',\n",
       "    'Integration Testing',\n",
       "    'Defect Tracking',\n",
       "    'Web Applications'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Software Test Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['HR',\n",
       "    'Counselling',\n",
       "    'Organizational Behaviour',\n",
       "    'Special Education'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Operations Management',\n",
       "    'Project Management',\n",
       "    'Risk Management',\n",
       "    'Compliance',\n",
       "    'Talent Management',\n",
       "    'Performance Management',\n",
       "    'Client Management',\n",
       "    'Billing',\n",
       "    'Application Support',\n",
       "    'Account Receivables',\n",
       "    'Credit Control'],\n",
       "   'candidate_experience': 17,\n",
       "   'candidate_profession': 'Operations Manager'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Drawing',\n",
       "    'Arts & Craft',\n",
       "    'Teaching',\n",
       "    'Co-ordination',\n",
       "    'Marketing'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Drawing & Arts & Craft Teacher'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['DevOps',\n",
       "    'CI/CD',\n",
       "    'Git',\n",
       "    'Bitbucket',\n",
       "    'Jenkins',\n",
       "    'Ansible',\n",
       "    'Maven',\n",
       "    'Ant',\n",
       "    'Shell Scripting',\n",
       "    'Linux',\n",
       "    'Core Java',\n",
       "    'C',\n",
       "    'Apache Tomcat',\n",
       "    'Deployment',\n",
       "    'Configuration Management',\n",
       "    'Automation',\n",
       "    'SDLC',\n",
       "    'STLC',\n",
       "    'Requirement Gathering',\n",
       "    'Documentation',\n",
       "    'Change Management',\n",
       "    'Build Engineering',\n",
       "    'Testing',\n",
       "    'Architecture'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Devops Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['HTML5',\n",
       "    'CSS3',\n",
       "    'Javascript',\n",
       "    'jQuery',\n",
       "    'Angular JS',\n",
       "    'Angular 4',\n",
       "    'SASS',\n",
       "    'Bootstrap',\n",
       "    'Photoshop',\n",
       "    'Visual Studio',\n",
       "    'UI Design',\n",
       "    'Web Design',\n",
       "    'Graphics Design',\n",
       "    'Client Communication'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Web Designer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Electrical Engineering',\n",
       "    'Solar Power',\n",
       "    'Electrical Wiring',\n",
       "    'Distribution Substation',\n",
       "    'Transmission Lines',\n",
       "    'Installation',\n",
       "    'Maintenance',\n",
       "    'Basic Computer',\n",
       "    'Electrical Machine'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Electrical Engineering'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Quality Engineering',\n",
       "    'MATLAB',\n",
       "    'PCB Design',\n",
       "    'C',\n",
       "    'MS Office',\n",
       "    'MS PowerPoint',\n",
       "    'Multisim',\n",
       "    'Keil',\n",
       "    'Latex',\n",
       "    'Internet Fundamentals',\n",
       "    'Software Knowledge',\n",
       "    'Hardware Knowledge',\n",
       "    'Protius',\n",
       "    'Micro wind'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Quality Engineer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['SQL',\n",
       "    'Oracle',\n",
       "    'R Programming',\n",
       "    'Python',\n",
       "    'Linear Regression',\n",
       "    'Machine Learning',\n",
       "    'Statistical Modelling',\n",
       "    'Data Science',\n",
       "    'Business Analytics',\n",
       "    'Database Administration',\n",
       "    'Capacity Planning',\n",
       "    'Installation',\n",
       "    'Configuration',\n",
       "    'Database Design',\n",
       "    'Migration',\n",
       "    'Security',\n",
       "    'Troubleshooting',\n",
       "    'Backup',\n",
       "    'Data Recovery',\n",
       "    'Linux',\n",
       "    'Communication',\n",
       "    'Leadership',\n",
       "    'Teamwork',\n",
       "    'Data Elicitation'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Application Database Administrator'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Special Education',\n",
       "    'Psychology',\n",
       "    'Organizational Behaviour',\n",
       "    'Human Resources',\n",
       "    'Counselling'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Web Design',\n",
       "    'Web Development',\n",
       "    'PHP',\n",
       "    '.NET',\n",
       "    'Information Technology'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Web Designer and Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Ant',\n",
       "    'Maven',\n",
       "    'Git',\n",
       "    'Bitbucket',\n",
       "    'Jenkins',\n",
       "    'Linux',\n",
       "    'Ansible',\n",
       "    'Shell Scripting',\n",
       "    'Requirement Gathering',\n",
       "    'Continuous Integration',\n",
       "    'Continuous Deployment',\n",
       "    'Software Development Life Cycle',\n",
       "    'Software Testing Life Cycle',\n",
       "    'Documentation',\n",
       "    'Reporting',\n",
       "    'Test Reports',\n",
       "    'DevOps',\n",
       "    'C',\n",
       "    'Core Java',\n",
       "    'Apache Tomcat',\n",
       "    'Deployment',\n",
       "    'Configuration Management',\n",
       "    'Change Management',\n",
       "    'Automation',\n",
       "    'Build Engineering',\n",
       "    'Release Management'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'DevOps Engineer'}],\n",
       " [{'candidate_name': 'Anonymous Candidate',\n",
       "   'candidate_skills': ['Project Management',\n",
       "    'Operations Management',\n",
       "    'SOW Review',\n",
       "    'RFQ Review',\n",
       "    'Client Relationship Management',\n",
       "    'Budget Management',\n",
       "    'Quality Management',\n",
       "    'Contract Management',\n",
       "    'Procurement',\n",
       "    'Site Coordination',\n",
       "    'Team Leadership',\n",
       "    'PLC',\n",
       "    'SCADA',\n",
       "    'DCS',\n",
       "    'HMI Development',\n",
       "    'Hardware Engineering',\n",
       "    'Software Engineering',\n",
       "    'System Architecture',\n",
       "    'Commissioning',\n",
       "    'Documentation',\n",
       "    'Resource Planning',\n",
       "    'Risk Management',\n",
       "    'ISO 9001',\n",
       "    'SAP',\n",
       "    'Data Analysis',\n",
       "    'Technical Support',\n",
       "    'Sales Support',\n",
       "    'EV Analysis'],\n",
       "   'candidate_experience': 24,\n",
       "   'candidate_profession': 'Operations Manager'},\n",
       "  {'candidate_name': 'Anonymous Candidate',\n",
       "   'candidate_skills': ['Data Analysis',\n",
       "    'Quantitative Analysis',\n",
       "    'Predictive Modeling',\n",
       "    'Machine Learning',\n",
       "    'Business Intelligence',\n",
       "    'Data Mining',\n",
       "    'Data Visualization',\n",
       "    'Python',\n",
       "    'R',\n",
       "    'Spark',\n",
       "    'Hadoop',\n",
       "    'Tableau',\n",
       "    'QlikSense',\n",
       "    'AWS LEX',\n",
       "    'TensorFlow',\n",
       "    'Selenium WebDriver',\n",
       "    'Hive',\n",
       "    'PySpark',\n",
       "    'Microsoft Face API',\n",
       "    'OpenCV',\n",
       "    'NLP',\n",
       "    'IBM Bluemix',\n",
       "    'IBM Watson',\n",
       "    'KPI Dashboards',\n",
       "    'Research',\n",
       "    'Project Management',\n",
       "    'Mentoring',\n",
       "    'Chatbot Development',\n",
       "    'Web Scraping',\n",
       "    'Fraud Detection',\n",
       "    'Churn Analysis',\n",
       "    'Sentiment Analysis'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Data Scientist'},\n",
       "  {'candidate_name': 'Anonymous Candidate',\n",
       "   'candidate_skills': ['C',\n",
       "    'C++',\n",
       "    'SQL',\n",
       "    'PL/SQL',\n",
       "    'Java',\n",
       "    'JavaEE',\n",
       "    'Javascript',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'Jquery',\n",
       "    'MySQL',\n",
       "    'Spring',\n",
       "    'Hibernate',\n",
       "    'Python',\n",
       "    'AWS',\n",
       "    'DevOps',\n",
       "    'FPGA',\n",
       "    'Cryptography',\n",
       "    'Robotics',\n",
       "    'RFID',\n",
       "    'GSM',\n",
       "    'Xilinx',\n",
       "    'Modelsim',\n",
       "    'Matlab',\n",
       "    'Multisim',\n",
       "    'Windows',\n",
       "    'Ubuntu'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'DevOps Engineer'},\n",
       "  {'candidate_name': 'Anonymous Candidate',\n",
       "   'candidate_skills': ['Communication',\n",
       "    'Networking',\n",
       "    'Teamwork',\n",
       "    'Project Management',\n",
       "    'Process Reengineering',\n",
       "    'Corporate Communications',\n",
       "    'MIS Reporting',\n",
       "    'Documentation',\n",
       "    'Training & Development',\n",
       "    'Sales Support',\n",
       "    'Operations Management',\n",
       "    'Business Analysis',\n",
       "    'Stakeholder Management',\n",
       "    'Customer Service',\n",
       "    'UAT',\n",
       "    'BRD',\n",
       "    'SOPs',\n",
       "    'SLAs',\n",
       "    'Campaign Strategies',\n",
       "    'New Process Development',\n",
       "    'Customer Escalation Handling'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Senior Manager - PMO'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Web Design', 'PHP'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Web designer and Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Windows OS',\n",
       "    'MYSQL',\n",
       "    'SQL Server',\n",
       "    'Core Java',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'Manual Testing',\n",
       "    'Database Testing',\n",
       "    'Bug Tracking',\n",
       "    'Test Planning',\n",
       "    'Test Case Execution',\n",
       "    'Defect Tracking',\n",
       "    'Software Testing',\n",
       "    'Application Testing'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'JR TESTING ENGINEER'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['SAP Security',\n",
       "    'SAP GRC',\n",
       "    'Microsoft Excel',\n",
       "    'VBA Programming',\n",
       "    'Authorization Management',\n",
       "    'Troubleshooting',\n",
       "    'Project Management',\n",
       "    'Documentation',\n",
       "    'Design Skills',\n",
       "    'Analytical Thinking'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'SAP CONSULTANT'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Business Development',\n",
       "    'Arts Management',\n",
       "    'Strategic Planning',\n",
       "    'Program Management',\n",
       "    'Partnership Development',\n",
       "    'Budget Management',\n",
       "    'Team Leadership',\n",
       "    'Marketing',\n",
       "    'Communications',\n",
       "    'Event Planning',\n",
       "    'Project Management',\n",
       "    'Journalism',\n",
       "    'Audio Editing',\n",
       "    'Web Designing'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Head business development, arts'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'SQL',\n",
       "    'PL/SQL',\n",
       "    'C',\n",
       "    'C++',\n",
       "    'BootStrap',\n",
       "    'JSP',\n",
       "    'Ext JS',\n",
       "    'Eclipse',\n",
       "    'Toad',\n",
       "    'SoapBox',\n",
       "    'Postman',\n",
       "    'Oracle',\n",
       "    'MS-SQL',\n",
       "    'MS-Access',\n",
       "    'MS-Excel',\n",
       "    'Webservices',\n",
       "    'XML',\n",
       "    'JSON'],\n",
       "   'candidate_experience': 6,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Bizagi',\n",
       "    'MS Visio',\n",
       "    'Indigo Studio',\n",
       "    'MS Office',\n",
       "    'MS Word',\n",
       "    'MS Excel',\n",
       "    'MS Power Point',\n",
       "    'Smoke Testing',\n",
       "    'Sanity Testing',\n",
       "    'Integration Testing',\n",
       "    'Functional Testing',\n",
       "    'Acceptance Testing',\n",
       "    'UI Testing',\n",
       "    'Waterfall',\n",
       "    'Agile',\n",
       "    'Scrum',\n",
       "    'SQL',\n",
       "    'HPQC',\n",
       "    'RPA',\n",
       "    'Automation Assessment',\n",
       "    'Business Requirements Gathering',\n",
       "    'Functional Requirements Specification',\n",
       "    'Prototyping',\n",
       "    'Test Plan Design',\n",
       "    'Test Scenarios',\n",
       "    'Test Cases',\n",
       "    'UAT',\n",
       "    'Process Improvement',\n",
       "    'Decision Models',\n",
       "    'Inventory Management',\n",
       "    'BRD',\n",
       "    'SRS',\n",
       "    'Defect Tracking',\n",
       "    'Risk Monitoring',\n",
       "    'Status Tracking',\n",
       "    'Reporting'],\n",
       "   'candidate_experience': 47,\n",
       "   'candidate_profession': 'Senior Business Analyst - RPA'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['C++',\n",
       "    'C',\n",
       "    'Java',\n",
       "    'DS',\n",
       "    'JDBC',\n",
       "    'Hibernate',\n",
       "    'Java J2EE',\n",
       "    'Javascript',\n",
       "    'JQuery',\n",
       "    'Ajax',\n",
       "    'Ms office',\n",
       "    'Excel'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Multi-tasking',\n",
       "    'Collaborative',\n",
       "    'Optimistic Thinking',\n",
       "    'Effective teamleader',\n",
       "    'Team trainer',\n",
       "    'Visualizing work',\n",
       "    'Communication',\n",
       "    'MS office',\n",
       "    'Sales',\n",
       "    'Marketing Management',\n",
       "    'Lead Generation',\n",
       "    'Business Management'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Sales Manager'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['MS Office',\n",
       "    'AutoCAD',\n",
       "    'EPLAN',\n",
       "    'SAP-ERP',\n",
       "    'ETAP',\n",
       "    'Electrical Design',\n",
       "    'Project Management',\n",
       "    'ISO Standards',\n",
       "    'ATEX',\n",
       "    'NFPA',\n",
       "    'IEC',\n",
       "    'NEC',\n",
       "    'API Standards',\n",
       "    'Sales',\n",
       "    'Marketing',\n",
       "    'Operation & Maintenance',\n",
       "    'Hazardous Area Classification',\n",
       "    'Lightning Protection'],\n",
       "   'candidate_experience': 7,\n",
       "   'candidate_profession': 'Electrical Design Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['AutoCAD',\n",
       "    'MS Office',\n",
       "    'Drafting',\n",
       "    'Civil Engineering',\n",
       "    'Site Supervision',\n",
       "    'Construction Management',\n",
       "    'Quantity Surveying',\n",
       "    'Project Scheduling',\n",
       "    'Procurement',\n",
       "    'Excavation',\n",
       "    'Foundation',\n",
       "    'Waterproofing',\n",
       "    'RCC',\n",
       "    'Masonry',\n",
       "    'Plastering',\n",
       "    'Steel Fixing'],\n",
       "   'candidate_experience': 9,\n",
       "   'candidate_profession': 'Civil Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'Core Java',\n",
       "    'Advance Java',\n",
       "    'Linux',\n",
       "    'Windows',\n",
       "    'Oracle',\n",
       "    'MySQL',\n",
       "    'Derby',\n",
       "    'Eclipse',\n",
       "    'SonarQube',\n",
       "    'Putty',\n",
       "    'Requirements Gathering',\n",
       "    'Software Design',\n",
       "    'Code Review',\n",
       "    'Debugging',\n",
       "    'Performance Optimization'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Hadoop',\n",
       "    'MapReduce',\n",
       "    'HDFS',\n",
       "    'Hive',\n",
       "    'Sqoop',\n",
       "    'Java',\n",
       "    'Core Java',\n",
       "    'Scala',\n",
       "    'Spark',\n",
       "    'Hbase',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Shell Scripting',\n",
       "    'Linux',\n",
       "    'Windows',\n",
       "    'Git',\n",
       "    'Data Engineering',\n",
       "    'Data Transformation',\n",
       "    'Algorithm Optimization'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Hadoop Developer'}],\n",
       " [{'candidate_name': 'Jetalal Hiralal Gorbanjara',\n",
       "   'candidate_skills': ['Drawing', 'Teaching', 'Political Science'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Asst.Professor'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['PMO',\n",
       "    'ITIL Management',\n",
       "    'Process Improvement',\n",
       "    'Project Auditing',\n",
       "    'Project Planning',\n",
       "    'Scheduling',\n",
       "    'Risk Management',\n",
       "    'SLA Management',\n",
       "    'Resource Management',\n",
       "    'Workforce Management',\n",
       "    'Transition Management',\n",
       "    'Operations Management',\n",
       "    'CA Clarity',\n",
       "    'Visio',\n",
       "    'Microsoft Office',\n",
       "    'SAP HR',\n",
       "    'Confluence',\n",
       "    'MS Excel',\n",
       "    'MS Project',\n",
       "    'Sharepoint',\n",
       "    'Service Desk',\n",
       "    'Recruitment'],\n",
       "   'candidate_experience': 10,\n",
       "   'candidate_profession': 'Senior Executive PMO Consultant'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['KSA License',\n",
       "    'MS Office',\n",
       "    'AutoCAD',\n",
       "    'Project Planning',\n",
       "    'Site Supervision',\n",
       "    'Client Coordination',\n",
       "    'Drawing Preparation',\n",
       "    'Billing',\n",
       "    'Estimating',\n",
       "    'Material Management'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Civil Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['HR', 'Economics'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['MS-Office',\n",
       "    'Communication',\n",
       "    'Convincing',\n",
       "    'Sales',\n",
       "    'Marketing',\n",
       "    'Customer Sales Management',\n",
       "    'Talent Management',\n",
       "    'Direct Sales Management'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Sales Manager'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Data Entry',\n",
       "    'Cold Calling',\n",
       "    'Sales',\n",
       "    'Salesforce',\n",
       "    'MS Office'],\n",
       "   'candidate_experience': 15,\n",
       "   'candidate_profession': 'Sales Manager'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Python'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Python Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['C',\n",
       "    'Java',\n",
       "    'HTML5',\n",
       "    'CSS3',\n",
       "    'Bootstrap',\n",
       "    'JavaScript',\n",
       "    'jQuery',\n",
       "    'Corel Draw',\n",
       "    'Photoshop',\n",
       "    'Illustrator',\n",
       "    'MySQL',\n",
       "    'Web Design',\n",
       "    'Graphics Design'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Web and Graphics Designer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['SAP HANA',\n",
       "    'SAP BO',\n",
       "    'Power BI',\n",
       "    'SQL',\n",
       "    'Data Modeling',\n",
       "    'Performance Tuning',\n",
       "    'SAP ECC',\n",
       "    'SLT',\n",
       "    'SDA',\n",
       "    'Charm/Solmon',\n",
       "    'HPALM',\n",
       "    'Remedy',\n",
       "    'WEBI'],\n",
       "   'candidate_experience': 7,\n",
       "   'candidate_profession': 'SAP HANA Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Operations Management',\n",
       "    'Logistics',\n",
       "    'Supply Chain Management',\n",
       "    'Freight Management',\n",
       "    'Inventory Management',\n",
       "    'Warehousing',\n",
       "    'Distribution',\n",
       "    'Procurement',\n",
       "    'Vendor Management',\n",
       "    'Customs Clearance',\n",
       "    'Export/Import',\n",
       "    'Team Leadership',\n",
       "    'MIS Reporting',\n",
       "    'Customer Service',\n",
       "    'ERP',\n",
       "    'MS Office',\n",
       "    'Tally',\n",
       "    'Underwriting'],\n",
       "   'candidate_experience': 22,\n",
       "   'candidate_profession': 'Operations Manager'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['HR Management',\n",
       "    'Payroll Management',\n",
       "    'Statutory Compliance',\n",
       "    'Performance Management',\n",
       "    'Recruitment & Selection',\n",
       "    'Training & Development',\n",
       "    'Employee Relations',\n",
       "    'Employee Engagement',\n",
       "    'Compensation & Benefits',\n",
       "    'MS Office',\n",
       "    'Saral Payment Package'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'HR'},\n",
       "  {'candidate_name': 'MANISH PRABHAKAR PATIL',\n",
       "   'candidate_skills': ['ETL',\n",
       "    'Informatica',\n",
       "    'SQL',\n",
       "    'Unix',\n",
       "    'Data Warehouse',\n",
       "    'Ab Initio',\n",
       "    'Datastage'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'ETL Informatica Developer'}],\n",
       " [{'candidate_name': 'MR. MANISH PRABHAKAR PATIL',\n",
       "   'candidate_skills': ['SQL',\n",
       "    'Unix',\n",
       "    'Data Warehouse',\n",
       "    'Ab Initio',\n",
       "    'ETL',\n",
       "    'Datastage',\n",
       "    'Informatica'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'ETL Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Python'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Python Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Informatica',\n",
       "    'ETL',\n",
       "    'Oracle',\n",
       "    'SQL',\n",
       "    'PL/SQL',\n",
       "    'UNIX',\n",
       "    'Facets',\n",
       "    'Tidal',\n",
       "    'JIRA',\n",
       "    'Putty'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'ETL Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['C',\n",
       "    'SQL',\n",
       "    'PL/SQL',\n",
       "    'Java',\n",
       "    'JavaEE',\n",
       "    'Javascript',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'jQuery',\n",
       "    'MySQL',\n",
       "    'Spring',\n",
       "    'Hibernate',\n",
       "    'C++',\n",
       "    'Python',\n",
       "    'DevOps',\n",
       "    'AWS'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'DevOps Engineer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['C#',\n",
       "    '.NET',\n",
       "    'ASP.NET MVC',\n",
       "    'Web API',\n",
       "    'Angular',\n",
       "    'jQuery',\n",
       "    'HTML5',\n",
       "    'CSS3',\n",
       "    'Bootstrap',\n",
       "    'SQL Server',\n",
       "    'Visual Studio',\n",
       "    'MS-Office',\n",
       "    'ASP',\n",
       "    'Entity Framework'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'DOT NET Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['SAP ABAP',\n",
       "    'ALE',\n",
       "    'IDOC',\n",
       "    'oDATA',\n",
       "    'Fiori',\n",
       "    'SAP S/4HANA',\n",
       "    'EWM',\n",
       "    'APO',\n",
       "    'SAP Retail',\n",
       "    'EDI',\n",
       "    'SAP Netweaver Gateway',\n",
       "    'SAP Techno Functional',\n",
       "    'IS-Retail',\n",
       "    'IS-Auto',\n",
       "    'SAP SD',\n",
       "    'Extensibility',\n",
       "    'Embedded Analytics',\n",
       "    'ITIL',\n",
       "    'PRINCE2',\n",
       "    'SAP MM',\n",
       "    'SAP FI',\n",
       "    'SAP CO',\n",
       "    'SAP PS',\n",
       "    'SAP PP',\n",
       "    'SAP CS',\n",
       "    'SAP PM',\n",
       "    'SAP QM',\n",
       "    'SAP HR',\n",
       "    'SAP SCM',\n",
       "    'SAP SOLMAN',\n",
       "    'SAP GTS',\n",
       "    'SAP PI',\n",
       "    'SAP BI'],\n",
       "   'candidate_experience': 13,\n",
       "   'candidate_profession': 'SAP Technical Architect'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Windows',\n",
       "    'Linux',\n",
       "    'Ubuntu',\n",
       "    'RHEL',\n",
       "    'Cisco Routing',\n",
       "    'Cisco Switching',\n",
       "    'Cisco Firewall',\n",
       "    'Fortinet Firewall',\n",
       "    'VLAN',\n",
       "    'ACL',\n",
       "    'OSPF',\n",
       "    'EIGRP',\n",
       "    'STP',\n",
       "    'IPv6',\n",
       "    'LAN',\n",
       "    'WAN',\n",
       "    'DHCP',\n",
       "    'DNS',\n",
       "    'FTP',\n",
       "    'Active Directory',\n",
       "    'SCCM',\n",
       "    'Group Policies',\n",
       "    'VMWare ESXi',\n",
       "    'Symantec Backup EXEC',\n",
       "    'GNS3 Network Simulator'],\n",
       "   'candidate_experience': 4,\n",
       "   'candidate_profession': 'Sr. Network Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['ETL',\n",
       "    'Data Warehousing',\n",
       "    'SQL',\n",
       "    'PL SQL',\n",
       "    'Java',\n",
       "    'Python',\n",
       "    'SAP BODS',\n",
       "    'SAP BO',\n",
       "    'Oracle',\n",
       "    'Sybase',\n",
       "    'SAP R3',\n",
       "    'SCD',\n",
       "    'Apache',\n",
       "    'Tomcat',\n",
       "    'Repository Management',\n",
       "    'Web Intelligence',\n",
       "    'BO Mobile',\n",
       "    'Trusted Authentication',\n",
       "    'Vintela SSO'],\n",
       "   'candidate_experience': 6,\n",
       "   'candidate_profession': 'SAP BO/BODS Developer/Administrator'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['English',\n",
       "    'Hindi',\n",
       "    'Punjabi',\n",
       "    'Communication',\n",
       "    'Administrative Procedures',\n",
       "    'Evidence Rules',\n",
       "    'Trials',\n",
       "    'Microsoft Certified Systems Engineer',\n",
       "    'Windows',\n",
       "    'Word Processing',\n",
       "    'Legal Research',\n",
       "    'Microsoft Office',\n",
       "    'Drafting',\n",
       "    'Legal Advice',\n",
       "    'Case Pleading',\n",
       "    'Legal Documentation',\n",
       "    'Settlement Negotiation',\n",
       "    'Mediation',\n",
       "    'Arbitration',\n",
       "    'Practice Management'],\n",
       "   'candidate_experience': 6,\n",
       "   'candidate_profession': 'Advocate'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Cisco ASA',\n",
       "    'Checkpoint Firewall',\n",
       "    'Palo Alto Firewall',\n",
       "    'F5 LTM',\n",
       "    'Network Security',\n",
       "    'Cisco Routers',\n",
       "    'Cisco Switches',\n",
       "    'Juniper',\n",
       "    'Pulse Secure',\n",
       "    'RSA Envision',\n",
       "    'SIEM',\n",
       "    'IDS',\n",
       "    'IPS',\n",
       "    'Qualis',\n",
       "    'Python',\n",
       "    'VB Scripting',\n",
       "    'ITIL',\n",
       "    'Incident Management',\n",
       "    'Change Management',\n",
       "    'Problem Management',\n",
       "    'HLD',\n",
       "    'LLD',\n",
       "    'Network Design',\n",
       "    'SSL VPN',\n",
       "    '2FA',\n",
       "    'Security Event Analysis',\n",
       "    'Configuration Management'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Senior Network security Analyst'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Autocad',\n",
       "    'Solidworks',\n",
       "    'Catia',\n",
       "    'Mechanical Design',\n",
       "    'Design Engineering',\n",
       "    'Project Management'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Design Engineer (Mechanical)'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Fitness',\n",
       "    'Personal Training',\n",
       "    'American College of Sports Science',\n",
       "    'Heart Saver',\n",
       "    'REPS Level 3'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Personal Fitness Trainer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Java',\n",
       "    'J2EE',\n",
       "    'Spring',\n",
       "    'Hibernate',\n",
       "    'Angular',\n",
       "    'PostgreSQL',\n",
       "    'MySQL',\n",
       "    'Linux',\n",
       "    'Manual Testing',\n",
       "    'Functional Testing',\n",
       "    'C',\n",
       "    'C++'],\n",
       "   'candidate_experience': 7,\n",
       "   'candidate_profession': 'Java Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Electrical Maintenance',\n",
       "    'Troubleshooting',\n",
       "    'Mechanical Maintenance',\n",
       "    'Diesel Generator',\n",
       "    'HT/LT Switchgear',\n",
       "    'Relays',\n",
       "    'Circuit Breaker',\n",
       "    'Transformer',\n",
       "    'STP',\n",
       "    'WTP Plant',\n",
       "    'PLC/SCADA',\n",
       "    'UPS',\n",
       "    'Motor Testing',\n",
       "    'Power Factor Correction',\n",
       "    'MCC Panel',\n",
       "    'PCC Panel',\n",
       "    'Electrical Safety',\n",
       "    'Preventive Maintenance'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Electrical Engineer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Basic Computer',\n",
       "    'Electrical Machine',\n",
       "    'Electrical Wiring',\n",
       "    'Solar Power Plant',\n",
       "    'Distribution Substation',\n",
       "    'Installation',\n",
       "    'Maintenance',\n",
       "    'Transmission Line'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Electrical Engineering'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Cloud Computing',\n",
       "    'DevOps',\n",
       "    'AWS',\n",
       "    'Azure',\n",
       "    'Shell Scripting',\n",
       "    'Python',\n",
       "    'Automation',\n",
       "    'Solution Architecture',\n",
       "    'Linux',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Puppet',\n",
       "    'CI/CD',\n",
       "    'Monitoring',\n",
       "    'Team Leadership',\n",
       "    'EC2',\n",
       "    'RDS',\n",
       "    'CloudFormation',\n",
       "    'Lambda',\n",
       "    'DynamoDB',\n",
       "    'CloudWatch',\n",
       "    'Auto-scaling',\n",
       "    'Elastic Beanstalk',\n",
       "    'Appdynamics',\n",
       "    'Tibco Spotfire',\n",
       "    'Production Deployment',\n",
       "    'Unix',\n",
       "    'Redhat Satellite',\n",
       "    'Application Support',\n",
       "    'Patching',\n",
       "    'Troubleshooting',\n",
       "    'Windows',\n",
       "    'RHDS',\n",
       "    'CVS',\n",
       "    'VDI',\n",
       "    'SQL',\n",
       "    'HTML',\n",
       "    'IBM AIX',\n",
       "    'Filenet',\n",
       "    'Database Replication',\n",
       "    'Database Backup'],\n",
       "   'candidate_experience': 8,\n",
       "   'candidate_profession': 'Cloud Operations Architect (DevOps)'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Python',\n",
       "    'Django',\n",
       "    'DRF',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'SQLite',\n",
       "    'MongoDB',\n",
       "    'CSS',\n",
       "    'HTML',\n",
       "    'RESTful Web Services',\n",
       "    'REST',\n",
       "    'Agile',\n",
       "    'Scrum',\n",
       "    'GitHub',\n",
       "    'Jira',\n",
       "    'Windows',\n",
       "    'Unix',\n",
       "    'Logger',\n",
       "    'JSON'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Python Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Bitcoin',\n",
       "    'Ethereum',\n",
       "    'Solidity',\n",
       "    'Hyperledger',\n",
       "    'Go',\n",
       "    'R3 Corda',\n",
       "    'Tendermint',\n",
       "    'Node.js',\n",
       "    'C Programming',\n",
       "    'Java',\n",
       "    'Machine Learning',\n",
       "    'Brain Computer Interface',\n",
       "    'Computer Networking',\n",
       "    'Server Admin',\n",
       "    'Computer Vision',\n",
       "    'Data Analytics',\n",
       "    'Cloud Computing',\n",
       "    'React.js',\n",
       "    'Angular'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Blockchain Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Communication',\n",
       "    'Networking',\n",
       "    'Teamwork',\n",
       "    'Multi-tasking',\n",
       "    'Strategies',\n",
       "    'Campaigns',\n",
       "    'Corporate Communications',\n",
       "    'MIS Reporting',\n",
       "    'Documentation',\n",
       "    'Training & Development',\n",
       "    'Sales Support',\n",
       "    'Back Office Operations',\n",
       "    'New Process Development',\n",
       "    'Customer Escalations',\n",
       "    'Operations',\n",
       "    'Sales',\n",
       "    'Project Management',\n",
       "    'Process Reengineering'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Senior Manager - PMO'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Ant',\n",
       "    'Maven',\n",
       "    'GIT',\n",
       "    'Bitbucket',\n",
       "    'Jenkins',\n",
       "    'Linux',\n",
       "    'Ansible',\n",
       "    'Shell Scripting',\n",
       "    'Requirement Gathering',\n",
       "    'Continuous Integration',\n",
       "    'Continuous Deployment',\n",
       "    'Software Development Life Cycle',\n",
       "    'Software Testing Life Cycle',\n",
       "    'Documentation',\n",
       "    'Reporting',\n",
       "    'Test Reports',\n",
       "    'DevOps Methodologies',\n",
       "    'C',\n",
       "    'Core Java',\n",
       "    'Apache Tomcat',\n",
       "    'Deployment',\n",
       "    'Change Management',\n",
       "    'Configuration Management',\n",
       "    'Automation',\n",
       "    'Build Engineering'],\n",
       "   'candidate_experience': 2,\n",
       "   'candidate_profession': 'Devops Engineer'}],\n",
       " [{'candidate_name': None,\n",
       "   'candidate_skills': ['Legal'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'Advocate'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Agile Methodology',\n",
       "    'Scrum',\n",
       "    'Kanban',\n",
       "    'Test-driven development (TDD)',\n",
       "    'Feature Driven development (FDD)',\n",
       "    'Industrial Automation',\n",
       "    'Retail',\n",
       "    'Banking',\n",
       "    'Insurance',\n",
       "    'Health care',\n",
       "    'Automation Framework',\n",
       "    'HP UFT',\n",
       "    'Load Runner',\n",
       "    'Selenium',\n",
       "    'Rational Robot',\n",
       "    'DCMTK',\n",
       "    'Sikuli',\n",
       "    'VB Script',\n",
       "    'C++',\n",
       "    'Python',\n",
       "    'Shell Script',\n",
       "    'Bugzilla',\n",
       "    'Jira',\n",
       "    'HP Quality Control',\n",
       "    'Clear Quest',\n",
       "    'Clear Case',\n",
       "    'SVN',\n",
       "    'Oracle',\n",
       "    'SQL Server',\n",
       "    'MySQL',\n",
       "    'TCP/IP',\n",
       "    'HTTP',\n",
       "    'HTTPS',\n",
       "    'VPN',\n",
       "    'FTP',\n",
       "    'LDAP',\n",
       "    'DICOM',\n",
       "    'PACS',\n",
       "    'HL7',\n",
       "    'Image Archiving',\n",
       "    'Image Reconstruction',\n",
       "    'Rockwell Automation Logix Designer',\n",
       "    'Factory Talk',\n",
       "    'RSLinx Classic',\n",
       "    'Control Flash',\n",
       "    'Compare Tool',\n",
       "    'I/O modules',\n",
       "    'QTP',\n",
       "    'Test Automation Framework (TAF)'],\n",
       "   'candidate_experience': 9,\n",
       "   'candidate_profession': 'QA Automation Lead'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['ASP.NET',\n",
       "    'MVC',\n",
       "    'Unit Testing',\n",
       "    'Entity Framework',\n",
       "    'C#',\n",
       "    'JavaScript',\n",
       "    'JQuery',\n",
       "    'Angular1.5',\n",
       "    'Typescript',\n",
       "    'Visual Studio',\n",
       "    '.NET Framework',\n",
       "    'SQL Server',\n",
       "    'Tortoise SVN',\n",
       "    'Git',\n",
       "    'Knockout JS',\n",
       "    'Web API',\n",
       "    'WCF',\n",
       "    'JSON',\n",
       "    'LINQ',\n",
       "    'HTML 5',\n",
       "    'Agile',\n",
       "    'Test Driven Development'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Dot Net Developer'},\n",
       "  {'candidate_name': None,\n",
       "   'candidate_skills': ['Informatica',\n",
       "    'ETL',\n",
       "    'Oracle',\n",
       "    'SQL',\n",
       "    'PL-SQL',\n",
       "    'UNIX',\n",
       "    'Facets',\n",
       "    'Tidal',\n",
       "    'JIRA',\n",
       "    'Putty',\n",
       "    'Informatica PowerCenter',\n",
       "    'Data Warehousing',\n",
       "    'Data Integration'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'ETL Developer'}],\n",
       " [{'candidate_skills': ['Manual Testing',\n",
       "    'Automation Testing',\n",
       "    'Selenium IDE',\n",
       "    'TestNG',\n",
       "    'Selenium Grid',\n",
       "    'Jenkins',\n",
       "    'Apache POI',\n",
       "    'SDLC',\n",
       "    'White Box Testing',\n",
       "    'Black Box Testing',\n",
       "    'Functional Testing',\n",
       "    'Integration Testing',\n",
       "    'System Testing',\n",
       "    'Test Case Design',\n",
       "    'Defect Tracking',\n",
       "    'STLC',\n",
       "    'JDBC',\n",
       "    'Servlets',\n",
       "    'JSP',\n",
       "    'Web Applications',\n",
       "    'MS Access'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Software Test Engineer'},\n",
       "  {'candidate_skills': ['C',\n",
       "    'Matlab',\n",
       "    'Keil',\n",
       "    'Latex',\n",
       "    'Protius',\n",
       "    'Multisim',\n",
       "    'Microwind',\n",
       "    'PCB Design',\n",
       "    'MS Office',\n",
       "    'MS Power Point'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Quality Engineer'},\n",
       "  {'candidate_skills': ['Python',\n",
       "    'Django',\n",
       "    'DRF',\n",
       "    'MySQL',\n",
       "    'Oracle',\n",
       "    'Sqlite',\n",
       "    'MongoDB',\n",
       "    'CSS',\n",
       "    'HTML',\n",
       "    'RESTful Web Services',\n",
       "    'REST',\n",
       "    'Agile',\n",
       "    'Scrum',\n",
       "    'Github',\n",
       "    'Jira',\n",
       "    'Windows',\n",
       "    'Unix',\n",
       "    'JSON'],\n",
       "   'candidate_experience': 3,\n",
       "   'candidate_profession': 'Python Developer'},\n",
       "  {'candidate_skills': ['C',\n",
       "    'C++',\n",
       "    'Java',\n",
       "    'Python',\n",
       "    'Numpy',\n",
       "    'Pandas',\n",
       "    'Matplotlib',\n",
       "    'Requests',\n",
       "    'Beautiful Soup',\n",
       "    'MySQL',\n",
       "    'Django',\n",
       "    'HTML',\n",
       "    'Web Scrapping',\n",
       "    'Tk',\n",
       "    'MS Excel',\n",
       "    'MS Office',\n",
       "    'MS Power Point',\n",
       "    'Windows'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Python Developer and Data Analyst'}],\n",
       " [{'candidate_name': 'Dongare Mandakini Murlidhar',\n",
       "   'candidate_skills': ['C',\n",
       "    'C++',\n",
       "    'Windows',\n",
       "    'Electronic System Testing',\n",
       "    'Test Plan Development',\n",
       "    'Troubleshooting',\n",
       "    'Hardware Testing',\n",
       "    'PCB Debugging',\n",
       "    'Quality Control',\n",
       "    'Quality Management'],\n",
       "   'candidate_experience': 1,\n",
       "   'candidate_profession': 'Electronics Engineer'},\n",
       "  {'candidate_name': 'Jayashree H .K',\n",
       "   'candidate_skills': ['C',\n",
       "    'C++',\n",
       "    'Java',\n",
       "    'Web Programming',\n",
       "    'MATLAB',\n",
       "    'DBMS',\n",
       "    'Database Management'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'},\n",
       "  {'candidate_name': 'Unknown Candidate',\n",
       "   'candidate_skills': ['MS Office',\n",
       "    'ERP',\n",
       "    'Tally',\n",
       "    'SAGE',\n",
       "    'Flotilla',\n",
       "    'WMS',\n",
       "    'Exceed 4000',\n",
       "    'Operations Management',\n",
       "    'Logistics',\n",
       "    'Supply Chain Management',\n",
       "    'Shipping',\n",
       "    'Imports',\n",
       "    'Warehousing',\n",
       "    'Distribution',\n",
       "    'Vendor Management',\n",
       "    'Freight Management',\n",
       "    'Customs Clearance',\n",
       "    'Inventory Control',\n",
       "    'Procurement',\n",
       "    'HR',\n",
       "    'Team Leadership',\n",
       "    'Customer Service',\n",
       "    'MIS Reporting',\n",
       "    'Underwriting',\n",
       "    'Documentation'],\n",
       "   'candidate_experience': 11,\n",
       "   'candidate_profession': 'Operations Manager'},\n",
       "  {'candidate_name': 'Unknown Candidate',\n",
       "   'candidate_skills': ['HR'],\n",
       "   'candidate_experience': 0,\n",
       "   'candidate_profession': 'HR'}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneshot_jsons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d0fd4",
   "metadata": {},
   "source": [
    "### 3. Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aedabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAMPLE_JSON_PATH, \"r\") as f:\n",
    "    sample_json = json.load(f)\n",
    "\n",
    "# limit to first 3 examples\n",
    "sample_json = list(sample_json.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b51631",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_resume_2 = None\n",
    "sample_resume_3 = None\n",
    "\n",
    "with open(SAMPLE_RESUME_2_PATH, \"r\") as file:\n",
    "    sample_resume_2 = file.read()\n",
    "    \n",
    "with open(SAMPLE_RESUME_3_PATH, \"r\") as file:\n",
    "    sample_resume_3 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd465c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"datasets/part1/task1/kaggle_outputs.json\"\n",
    "fewshot_jsons = []\n",
    "\n",
    "fewshot_system_prompt = \"\"\" \n",
    "    You are a master data analyst and annotator, especially skilled in creating JSON objects from rows of a dataframe.\n",
    "    You will be provided a dataframe batch, and your job is to convert them into JSON objects for each row.\n",
    "    Only Categories: \"candidate_name\", \"candidate_skills\", \"candidate_experience\", \"candidate_profession\"\n",
    "\"\"\"\n",
    "\n",
    "fewshot_user_prompt = \"\"\"\n",
    "    Given a row of data, your job is to convert this row into a JSON object. Analyse the following example for reference...\n",
    "    \n",
    "    Sample row 1:\n",
    "    {sample_row_1}\n",
    "    \n",
    "    Sample JSON 1:\n",
    "    {sample_json_1}\n",
    "    \n",
    "    Sample row 2:\n",
    "    {sample_row_2}\n",
    "    \n",
    "    Sample JSON 2:\n",
    "    {sample_json_2}\n",
    "    \n",
    "    Sample row 3:\n",
    "    {sample_row_3}\n",
    "    \n",
    "    Sample JSON 3:\n",
    "    {sample_json_3}\n",
    "    \n",
    "    Now, convert these rows into JSON:\n",
    "    {batch}\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "fewshot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", fewshot_system_prompt),\n",
    "    (\"user\", fewshot_user_prompt),\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "fewshot_chain = fewshot_prompt_template | llm | json_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #173\n",
      "Batch #174\n",
      "Batch #174\n",
      "Batch #175\n",
      "Batch #175\n",
      "Batch #176\n",
      "Batch #176\n",
      "Batch #177\n",
      "Batch #177\n",
      "Batch #178\n",
      "Batch #178\n",
      "Batch #179\n",
      "Batch #179\n",
      "Batch #180\n",
      "Batch #180\n",
      "Batch #181\n",
      "Batch #181\n",
      "Batch #182\n",
      "Batch #182\n",
      "Batch #183\n",
      "Batch #183\n",
      "Batch #184\n",
      "Batch #184\n",
      "Batch #185\n",
      "Batch #185\n",
      "Batch #186\n",
      "Batch #186\n",
      "Batch #187\n",
      "Batch #187\n",
      "Batch #188\n",
      "Batch #188\n",
      "Batch #189\n",
      "Batch #189\n",
      "Batch #190\n",
      "Batch #190\n",
      "Batch #191\n",
      "Batch #191\n",
      "Batch #192\n",
      "Batch #192\n",
      "Batch #193\n",
      "Batch #193\n",
      "Batch #194\n",
      "Batch #194\n",
      "Batch #195\n",
      "Batch #195\n",
      "Batch #196\n",
      "Batch #196\n",
      "Batch #197\n",
      "Batch #197\n",
      "Batch #198\n",
      "Batch #198\n",
      "Batch #199\n",
      "Batch #199\n",
      "Batch #200\n",
      "Batch #200\n",
      "Batch #201\n",
      "Batch #201\n",
      "Batch #202\n",
      "Batch #202\n",
      "Batch #203\n",
      "Batch #203\n",
      "Batch #204\n",
      "Batch #204\n",
      "Batch #205\n",
      "Batch #205\n",
      "Batch #206\n",
      "Batch #206\n",
      "Batch #207\n",
      "Batch #207\n",
      "Batch #208\n",
      "Batch #208\n",
      "Batch #209\n",
      "Batch #209\n",
      "Batch #210\n",
      "Batch #210\n",
      "Batch #211\n",
      "Batch #211\n",
      "Batch #212\n",
      "Batch #212\n",
      "Batch #213\n",
      "Batch #213\n",
      "Batch #214\n",
      "Batch #214\n",
      "Batch #215\n",
      "Batch #215\n",
      "Batch #216\n",
      "Batch #216\n",
      "Batch #217\n",
      "Batch #217\n",
      "Batch #218\n",
      "Batch #218\n",
      "Batch #219\n",
      "Batch #219\n",
      "Batch #220\n",
      "Batch #220\n",
      "Batch #221\n",
      "Batch #221\n",
      "Batch #222\n",
      "Batch #222\n",
      "Batch #223\n",
      "Batch #223\n",
      "Batch #224\n",
      "Batch #224\n",
      "Batch #225\n",
      "Batch #225\n",
      "Batch #226\n",
      "Batch #226\n",
      "Batch #227\n",
      "Batch #227\n",
      "Batch #228\n",
      "Batch #228\n",
      "Batch #229\n",
      "Batch #229\n",
      "Batch #230\n",
      "Batch #230\n",
      "Batch #231\n",
      "Batch #231\n",
      "Batch #232\n",
      "Batch #232\n",
      "Batch #233\n",
      "Batch #233\n",
      "Batch #234\n",
      "Batch #234\n",
      "Batch #235\n",
      "Batch #235\n",
      "Batch #236\n",
      "Batch #236\n",
      "Batch #237\n",
      "Batch #237\n",
      "Batch #238\n",
      "Batch #238\n",
      "Batch #239\n",
      "Batch #239\n",
      "Batch #240\n",
      "Batch #240\n",
      "Batch #241\n",
      "Batch #241\n"
     ]
    }
   ],
   "source": [
    "# LLM generated code to process batches of full dataset, saving every batch\n",
    "\n",
    "# Load previous results if file exists\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        fewshot_jsons = json.load(file)\n",
    "start_batch = len(fewshot_jsons)\n",
    "batch_size = 4\n",
    "\n",
    "for i, batch in enumerate(batch_iterator(resumes_df, batch_size)):\n",
    "    if i < start_batch:\n",
    "        continue  # Skip already processed batches\n",
    "\n",
    "    print(f\"Batch #{i+1}\")\n",
    "    batch_text = \"\\n---\\n\".join(batch['Resume'].astype(str).tolist())\n",
    "    try:\n",
    "        message = fewshot_chain.invoke({\n",
    "            \"sample_row_1\": sample_resume, \n",
    "            \"sample_json_1\": sample_json[0][1],\n",
    "            \n",
    "            \"sample_row_2\": sample_resume_2, \n",
    "            \"sample_json_2\": sample_json[1][1], \n",
    "            \n",
    "            \"sample_row_3\": sample_resume_3, \n",
    "            \"sample_json_3\": sample_json[2][1], \n",
    "            \n",
    "            \"batch\": batch_text,\n",
    "        })\n",
    "        \n",
    "        fewshot_jsons.append(message)\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(fewshot_jsons, file, ensure_ascii=False, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(\"Quota likely exhausted or API key expired. Progress saved. Please switch API key and rerun.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results for this in the datasets/task1/kaggle_outputs.json file\n",
    "# I'm assuming this means the few-shot only\n",
    "with open(\"datasets/part1/task1/kaggle_outputs.json\", \"w+\", encoding=\"utf-8\") as file:\n",
    "    json.dump(fewshot_jsons, file, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e74dcc",
   "metadata": {},
   "source": [
    "### **Reflective Question:** Comment on the quality of LLM responses under each prompting technique. Which one is better in this case, and in what scenario(s) would we choose one technique over the other?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "All three strategies can convert the resumes to the specified JSON format. \n",
    "\n",
    "Zero-shot prompting, since its not given much context for the description of the fields, it tries to fit as much as it can in each field.\n",
    "\n",
    "One-shot and few-shot prompting can ascertain the field descriptions from the given examples, so they're more consistent.\n",
    "\n",
    "In this case, one-shot prompting is the better technique since it consumes less input tokens, and performs pretty consistently.\n",
    "\n",
    "If we had less restrictions on input tokens, we could go for the few-shot technique, otherwise one-shot is sufficient in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d859c19",
   "metadata": {},
   "source": [
    "## Task 2: Building a Job Hiring Assistant\n",
    "\n",
    "You are going to build an AI assistant that helps employers find the best candidates for a job.\n",
    "\n",
    "- Employers share job descriptions.  \n",
    "- Job seekers share their resumes.  \n",
    "- Your assistant's tasks are to:\n",
    "  1. Pull out important candidate details from the resume (like name, skills, and experience).  \n",
    "  2. Summarize the job description in a few clear sentences.  \n",
    "  3. Compare the candidate with the job and give a fit score, a recommended role, and notes on why they are a good fit.\n",
    "\n",
    "---\n",
    "\n",
    "### How the assistant works\n",
    "\n",
    "1. Extract candidate details from the resume.  \n",
    "   - Output should be a JSON with the same fields as in Task 1.\n",
    "\n",
    "2. Summarize the job description.  \n",
    "   - Make it short and easy to understand (2-3 sentences).  \n",
    "\n",
    "3. Evaluate the candidate.  \n",
    "   - Take the candidate info from step 1 and the job summary from step 2.  \n",
    "   - Decide how well the candidate fits the job.\n",
    "\n",
    "---\n",
    "\n",
    "### Flow of the pipeline\n",
    "\n",
    "1. Chain 1: Resume → Candidate Info (JSON)  \n",
    "2. Chain 2: Job Description → Summary (plain text)  \n",
    "3. Chain 3: Candidate Info + Job Summary → Fit Assessment (fit score, recommended role, alignment notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a2a87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Chains 1 and 2 should run at the same time (in parallel).  \n",
    "- Both Chains 1 and 2 should use **few-shot prompting**.\n",
    "- Evaluate this on the resumes from the Kaggle dataset.\n",
    "- Use the job description provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5def79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resumes_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27c4a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc_few_shot_examples = \"\"\"\n",
    "Example 1:\n",
    "Job Description: \"We are looking for a Marketing Manager to lead our digital strategy. You must be proficient in SEO, Google Analytics, and content creation. Experience with social media campaigns is a must. You will manage a team of 3.\"\n",
    "Summary: The company seeks a Marketing Manager to lead digital strategy and manage a small team. Key requirements include expertise in SEO, Google Analytics, content creation, and social media campaigns.\n",
    "\n",
    "Example 2:\n",
    "Job Description: \"Hiring a Senior Accountant to handle financial reporting and tax compliance. CPA certification is required. Must have 5+ years of experience with GAAP and Excel. Remote work available.\"\n",
    "Summary: A Senior Accountant is needed for financial reporting and tax compliance, requiring a CPA and 5+ years of GAAP/Excel experience. The role offers remote work options.\n",
    "\n",
    "Example 3:\n",
    "Job Description: \"Junior Graphic Designer wanted. Proficient in Adobe Creative Suite (Photoshop, Illustrator). Will work on branding and social media graphics. Portfolio required.\"\n",
    "Summary: Seeking a Junior Graphic Designer skilled in Adobe Creative Suite to create branding and social media assets. A portfolio is required for application.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49668655",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "We're hiring a full-stack developer to maintain backend services, build REST APIs,\n",
    "and collaborate on deploying scalable applications using Docker and PostgreSQL.\n",
    "\"\"\"\n",
    "\n",
    "job_description_system_prompt = \"\"\"\n",
    "You are an expert HR assistant. Summarize the following job description into 2-3 clear, concise sentences.\n",
    "Use these examples as a guide for the style and length:\n",
    "{job_desc_few_shot_examples}\n",
    "\"\"\"\n",
    "\n",
    "job_description_user_prompt = \"\"\"\n",
    "Summarize the following job description into 2-3 short sentences.\n",
    "{job_desc}\n",
    "\"\"\"\n",
    "\n",
    "job_desc_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", job_description_system_prompt.format(job_desc_few_shot_examples=job_desc_few_shot_examples)),\n",
    "    (\"human\", \"{job_description_user_prompt}\\n\\n{job_description}\")\n",
    "])\n",
    "\n",
    "evaluation_system_prompt = \"\"\"\n",
    "You are an expert Hiring Manager. \n",
    "Compare the extracted Candidate Info and the Job Summary provided.\n",
    "Determine how well the candidate fits the role.\n",
    "\n",
    "Output a JSON object with:\n",
    "- \"fit_score\": A score from 0 to 100.\n",
    "- \"recommended_role\": A specific role title that fits the candidate best based on the job.\n",
    "- \"alignment_notes\": A brief explanation (2-3 sentences) of why they are or aren't a good fit.\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", evaluation_system_prompt),\n",
    "    (\"human\", \"\"\"\n",
    "    Job Summary: \n",
    "    {job_summary}\n",
    "    \n",
    "    Candidate Info: \n",
    "    {candidate_info}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "evaluation_chain = evaluation_prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resume_chain = fewshot_prompt_template | llm | json_parser\n",
    "job_description_chain = job_desc_prompt_template | llm | StrOutputParser()\n",
    "evaluation_chain = evaluation_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db345ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulding parallel map\n",
    "resume_job_desc_map = RunnableMap({\"resume_chain_output\": resume_chain, \"job_desc_chain_output\": job_description_chain})\n",
    "full_hiring_pipeline = resume_job_desc_map | evaluation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c749500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hiring Assistant Pipeline (RunnableMap)...\n",
      "\n",
      "--- Processing Candidate 1 ---\n",
      "Error: \"Input to ChatPromptTemplate is missing variables {'job_summary', 'candidate_info'}.  Expected: ['candidate_info', 'job_summary'] Received: ['resume_chain_output', 'job_desc_chain_output']\\nNote: if you intended {job_summary} to be part of the string and not a variable, please escape it with double curly braces like: '{{job_summary}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \"\n",
      "--- Processing Candidate 2 ---\n",
      "Error: \"Input to ChatPromptTemplate is missing variables {'job_summary', 'candidate_info'}.  Expected: ['candidate_info', 'job_summary'] Received: ['resume_chain_output', 'job_desc_chain_output']\\nNote: if you intended {job_summary} to be part of the string and not a variable, please escape it with double curly braces like: '{{job_summary}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \"\n",
      "--- Processing Candidate 3 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Processing Candidate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# We invoke the pipeline with a dictionary containing ALL inputs \u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# required by ANY of the sub-chains.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfull_hiring_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Inputs for Chain 1 (Resume Extraction)\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_row_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_resume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_json_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_row_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_resume_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_json_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_row_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_resume_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_json_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Inputs for Chain 2 (JD Summary)\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob_description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob_description_user_prompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description_user_prompt\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Display Results\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended Role: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommended_role\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nlp-pa4/lib/python3.10/site-packages/langchain_core/runnables/base.py:3127\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3127\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3129\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nlp-pa4/lib/python3.10/site-packages/langchain_core/runnables/base.py:3853\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3848\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3849\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3850\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3851\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3852\u001b[0m         ]\n\u001b[0;32m-> 3853\u001b[0m         output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3854\u001b[0m             key: future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m   3855\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3856\u001b[0m         }\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nlp-pa4/lib/python3.10/site-packages/langchain_core/runnables/base.py:3854\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3848\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3849\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3850\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3851\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3852\u001b[0m         ]\n\u001b[1;32m   3853\u001b[0m         output \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m-> 3854\u001b[0m             key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3855\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3856\u001b[0m         }\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nlp-pa4/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nlp-pa4/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Running Hiring Assistant Pipeline (RunnableMap)...\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    resume_text = resumes_df.iloc[i]['Resume']\n",
    "    print(f\"--- Processing Candidate {i+1} ---\")\n",
    "    \n",
    "    try:\n",
    "\n",
    "        result = full_hiring_pipeline.invoke({\n",
    "            \"sample_row_1\": sample_resume, \n",
    "            \"sample_json_1\": sample_json[0][1],\n",
    "            \"sample_row_2\": sample_resume_2, \n",
    "            \"sample_json_2\": sample_json[1][1], \n",
    "            \"sample_row_3\": sample_resume_3, \n",
    "            \"sample_json_3\": sample_json[2][1], \n",
    "            \"batch\": resume_text,\n",
    "            \n",
    "            \"job_description\": job_description,\n",
    "            \"job_description_user_prompt\": job_description_user_prompt\n",
    "        })\n",
    "        \n",
    "        print(f\"Recommended Role: {result.get('recommended_role')}\")\n",
    "        print(f\"Fit Score: {result.get('fit_score')}\")\n",
    "        print(f\"Notes: {result.get('alignment_notes')}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409fcb5",
   "metadata": {},
   "source": [
    "# Task 3: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "In this task, you will implement a complete **RAG (Retrieval-Augmented Generation)** pipeline using LangChain.  \n",
    "The goal is to build a system that retrieves relevant document chunks from a knowledge base and uses them to answer questions accurately.\n",
    "\n",
    "The following resources have also been attached for your reference:\n",
    "\n",
    "[RAG Resource](https://medium.com/@callumjmac/implementing-rag-in-langchain-with-chroma-a-step-by-step-guide-16fc21815339)\n",
    "\n",
    "[Chroma Resource](https://docs.langchain.com/oss/python/integrations/vectorstores/chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc05ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 1: Set Up a Document Loader\n",
    "\n",
    "You first need to load your dataset (e.g., a PDF document) and convert it into text.  \n",
    "Use LangChain's `PyPDFLoader` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fdb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_PATH = \"datasets/part1/task2/document.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(BOOK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73794e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ef6dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech and Language Processing\n",
      "An Introduction to Natural Language Processing,\n",
      "Computational Linguistics, and Speech Recognition\n",
      "with Language Models\n",
      "Third Edition draft\n",
      "Daniel Jurafsky\n",
      "Stanford University\n",
      "James H. Martin\n",
      "University of Colorado at Boulder\n",
      "Copyright ©2025. All rights reserved.\n",
      "Draft of August 24, 2025. Comments and typos welcome!\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87618d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3467c90",
   "metadata": {},
   "source": [
    "### Step 2: Text Splitter – Making the Data Digestible\n",
    "\n",
    "Given the limited size of an LLM’s context window, it is not feasible for the model to process the entire text at once.\n",
    "Therefore, we divide the text into smaller chunks (tokens).\n",
    "\n",
    "To preserve context, we add some overlap between chunks so that each piece retains part of its surrounding context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d73719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM generated\n",
    "def text_splitter(document, chunk_size, chunk_overlap):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(document)\n",
    "\n",
    "DEFAULT_CHUNK_SIZE = 128\n",
    "DEFAULT_CHUNK_OVERLAP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0698ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_splitter(docs, DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83de0c",
   "metadata": {},
   "source": [
    "### Step 3: Converting tokens to Embeddings\n",
    "\n",
    "Next, use a pre-trained BERT model from HuggingFace to convert the text chunks into embeddings.\n",
    "These embeddings serve as numerical representations of the document text and will be stored for retrieval later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f655362",
   "metadata": {},
   "source": [
    "had to make this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d90aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=bert_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39c1bb",
   "metadata": {},
   "source": [
    "### Step 4: Store the embeddings in a Vector Store\n",
    "\n",
    "Once the embeddings are generated, store them in a Vector Store for efficient retrieval.\n",
    "The retriever will query this vector store to find relevant chunks based on semantic similarity.\n",
    "\n",
    "For this task, use the **Chroma Vector Store**, configured to run locally (in-memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93253df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = Chroma.from_documents(\n",
    "#     documents=text_chunks,\n",
    "#     embedding=hf_embeddings,\n",
    "#     collection_metadata={\"hnsw:space\": \"cosine\"},    # for cosine sim\n",
    "#     persist_directory=\"./vectorstores/Part1_Task3_RAG\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9388b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load store\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./vectorstores/Part1_Task3_RAG\",\n",
    "    embedding_function=hf_embeddings, \n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7578b9",
   "metadata": {},
   "source": [
    "### Step 5: Build a RAG chain\n",
    "\n",
    "Now, connect all components into a complete RAG chain:\n",
    "- Define a prompt template that integrates the retrieved context and the user query.\n",
    "- Connect this chain to your chosen LLM.\n",
    "\n",
    "The LLM will generate answers using both the retrieved context and its internal knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35dcf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_agent_system_prompt = \"\"\"\n",
    "You are a helpful assistant, skilful in using provided context to answer user queries. Use the following contexts to answer queries. Be helpful!\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_agent_user_prompt = \"\"\"\n",
    "Answer the following question:\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", rag_agent_system_prompt),\n",
    "    (\"user\", rag_agent_user_prompt)\n",
    "])\n",
    "\n",
    "rag_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "rag_chain = rag_prompt_template | rag_llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7b7e9",
   "metadata": {},
   "source": [
    "### Step 6: Query the System\n",
    "\n",
    "Query your RAG system using the following prompts.\n",
    "Your retriever should return the top-k elements from the vector store as context, where k = 5.\n",
    "\n",
    "For each query, store:\n",
    "1.\tThe average cosine similarity between the query vector and each of the top-5 retrieved document chunks (averaged across all queries).\n",
    "2.\tThe LLM-generated response for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106a47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What section is BPE training from? Also list the examples used for this algorithm in the book.\",\n",
    "    \"What formula does the book use for the Minimum Edit Distance algorithm?\",\n",
    "    # page 42\n",
    "    \"What problems are highlighted in the book when dealing with scale in large n-gram models?\",\n",
    "    # page 47\n",
    "    \"What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\",\n",
    "    # page 404\n",
    "    \"What examples does the book use to demonstrate syntactic constituency?\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ea6d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What section is BPE training from? Also list the examples used for this algorithm in the book.\n",
      "Answer: BPE training is illustrated in **Fig. 7.13**, suggesting it is from **Chapter 7**.\n",
      "\n",
      "The only specific example mentioned for the BPE algorithm in the provided context is **Fig. 7.13**, which illustrates the general training approach. Additionally, Andrej Karpathy's lecture (https://www.youtube.com/watch?v=zduSFxRajkE) is cited as a popular introduction to BPE.\n",
      "\n",
      "Avg Cosine Sim: 0.6476\n",
      "------------------------------\n",
      "Query 2: What formula does the book use for the Minimum Edit Distance algorithm?\n",
      "Answer: The provided context mentions the Minimum Edit Distance algorithm and refers to finding it as a \"search task,\" but it does not provide a specific formula for the algorithm.\n",
      "\n",
      "Avg Cosine Sim: 0.7906\n",
      "------------------------------\n",
      "Query 3: What problems are highlighted in the book when dealing with scale in large n-gram models?\n",
      "Answer: When dealing with scale in large n-gram models, the book highlights that language models can become \"very large,\" leading to \"practical issues.\" Efficiency considerations are also emphasized as important when building these large models.\n",
      "\n",
      "Avg Cosine Sim: 0.6971\n",
      "------------------------------\n",
      "Query 4: What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\n",
      "Answer: Based on the provided context:\n",
      "\n",
      "The context states that the technique of visualizing a language model by **sampling** was \"ﬁrst suggested.\" However, it does not explicitly mention that Shannon proposed this technique in 1948.\n",
      "\n",
      "The section containing content relevant to this topic is:\n",
      "*   **3.4 Sampling sentences from a language model**\n",
      "\n",
      "Avg Cosine Sim: 0.5732\n",
      "------------------------------\n",
      "Query 5: What examples does the book use to demonstrate syntactic constituency?\n",
      "Answer: Based on the provided context, the book mentions \"immediate-constituent analysis\" as a method of syntactic study and that syntactic structure is often represented as dependency, but it does not provide specific examples to demonstrate syntactic constituency.\n",
      "\n",
      "Avg Cosine Sim: 0.6304\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "top_k = 5\n",
    "\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "\n",
    "    # get docs and scores\n",
    "    docs_and_scores = vectorstore.similarity_search_with_score(query, k=top_k)\n",
    "    \n",
    "    # get cosine sim\n",
    "    similarities = [1 - score for _, score in docs_and_scores]\n",
    "    avg_similarity = np.mean(similarities)\n",
    "    \n",
    "    # create context\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc, _ in docs_and_scores])\n",
    "    \n",
    "    # invoke chain\n",
    "    answer = rag_chain.invoke({\n",
    "        \"context\": context_text,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    # store results\n",
    "    results.append({\n",
    "        \"query\": query,\n",
    "        \"avg_similarity\": avg_similarity,\n",
    "        \"retrieved_docs\": docs_and_scores,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "    \n",
    "    print(f\"Query {i+1}: {query}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(f\"Avg Cosine Sim: {avg_similarity:.4f}\\n\" + \"-\"*30 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a4862",
   "metadata": {},
   "source": [
    "### **Reflective Question:** Did you get the expected results for each query? If not, then why do you think this may be so? What parameter(s) can we tune in this setup to improve performance?\n",
    "\n",
    "**Answer:**\n",
    "The system was unable to answer the queries completely; it seems like the context given does not lead to ideal answers. Maybe increasing the number of documents given as context can benefit the RAG system. Chunk size and chunk overlap also play a big role in this..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa96ba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Retrieval Analysis\n",
    "\n",
    "After querying, analyze the retrieval quality of your RAG system.\n",
    "\n",
    "Create a plot where:\n",
    "- The x-axis represents the retrieval ranking position (Chunk 1, Chunk 2, …, Chunk 5)\n",
    "- The y-axis shows the average cosine similarity score for chunks at that ranking position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "287fa79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'BPE training is illustrated in **Fig. 7.13**, suggesting it is '\n",
      "           'from **Chapter 7**.\\n'\n",
      "           '\\n'\n",
      "           'The only specific example mentioned for the BPE algorithm in the '\n",
      "           'provided context is **Fig. 7.13**, which illustrates the general '\n",
      "           \"training approach. Additionally, Andrej Karpathy's lecture \"\n",
      "           '(https://www.youtube.com/watch?v=zduSFxRajkE) is cited as a '\n",
      "           'popular introduction to BPE.',\n",
      " 'avg_similarity': np.float64(0.6476274371147156),\n",
      " 'query': 'What section is BPE training from? Also list the examples used for '\n",
      "          'this algorithm in the book.',\n",
      " 'retrieved_docs': [(Document(id='ecaf4147-bd07-4488-a0a5-569b4e59288c', metadata={'trapped': '/False', 'page': 266, 'title': '', 'page_label': '259', 'producer': 'pdfTeX-1.40.21', 'total_pages': 622, 'moddate': '2025-08-24T11:40:21-07:00', 'subject': '', 'keywords': '', 'source': 'datasets/part1/task2/document.pdf', 'creationdate': '2025-08-24T11:40:21-07:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'author': '', 'creator': 'LaTeX with hyperref'}, page_content='Rather than the simple BPE algorithm from Fig. 2.6, modern systems often use'),\n",
      "                     0.2964160442352295),\n",
      "                    (Document(id='bb420b96-c7f9-4967-a4db-ec099f85042f', metadata={'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'page_label': '13', 'title': '', 'keywords': '', 'source': 'datasets/part1/task2/document.pdf', 'subject': '', 'total_pages': 622, 'moddate': '2025-08-24T11:40:21-07:00', 'trapped': '/False', 'author': '', 'creationdate': '2025-08-24T11:40:21-07:00', 'page': 20}, page_content='Like most tokenization schemes, the BPE algorithm has two parts: a trainer,'),\n",
      "                     0.32145553827285767),\n",
      "                    (Document(id='05a17574-c507-45b3-b775-6301e7bbb4b4', metadata={'source': 'datasets/part1/task2/document.pdf', 'total_pages': 622, 'producer': 'pdfTeX-1.40.21', 'subject': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'title': '', 'page': 266, 'trapped': '/False', 'creator': 'LaTeX with hyperref', 'keywords': '', 'author': '', 'moddate': '2025-08-24T11:40:21-07:00', 'creationdate': '2025-08-24T11:40:21-07:00', 'page_label': '259'}, page_content='kenization algorithms, like the BPE algorithm sketched in Chapter 2. A shared'),\n",
      "                     0.3664255738258362),\n",
      "                    (Document(id='70dc4a87-a749-4aa9-952c-54a4b324379e', metadata={'title': '', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'keywords': '', 'moddate': '2025-08-24T11:40:21-07:00', 'page_label': '35', 'total_pages': 622, 'author': '', 'subject': '', 'page': 42, 'creationdate': '2025-08-24T11:40:21-07:00', 'creator': 'LaTeX with hyperref', 'trapped': '/False', 'source': 'datasets/part1/task2/document.pdf'}, page_content='who also has a popular lecture introducing BPE ( https://www.youtube.com/\\nwatch?v=zduSFxRajkE).'),\n",
      "                     0.3843711018562317),\n",
      "                    (Document(id='3f3aa262-48f6-4929-9ddd-9d8fff9cbbed', metadata={'moddate': '2025-08-24T11:40:21-07:00', 'source': 'datasets/part1/task2/document.pdf', 'creator': 'LaTeX with hyperref', 'page': 167, 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'page_label': '160', 'subject': '', 'creationdate': '2025-08-24T11:40:21-07:00', 'author': '', 'keywords': '', 'title': '', 'producer': 'pdfTeX-1.40.21', 'total_pages': 622, 'trapped': '/False'}, page_content='Fig. 7.13 illustrates the general training approach. At each step, given all the'),\n",
      "                     0.3931945562362671)]}\n"
     ]
    }
   ],
   "source": [
    "pprint(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e652e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rank_scores = [[] for _ in range(top_k)]\n",
    "\n",
    "for res in results:\n",
    "    docs_scores = res['retrieved_docs']\n",
    "    for rank, (doc, score) in enumerate(docs_scores):\n",
    "        \n",
    "        # convert to similarity\n",
    "        similarity = 1 - score\n",
    "        rank_scores[rank].append(similarity)\n",
    "\n",
    "# calculate mean\n",
    "avg_scores_per_rank = [np.mean(scores) for scores in rank_scores]\n",
    "ranks = list(range(1, top_k + 1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ranks, avg_scores_per_rank)\n",
    "plt.title(f'Average Cosine Similarity vs. Retrieval Rank (k={top_k})')\n",
    "plt.xlabel('Rank Position')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.xticks(ranks)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785694b",
   "metadata": {},
   "source": [
    "### **Reflective Question:** Comment on the trend observed. Is it what we're expecting? Why or why not?\n",
    "**Answer:**\n",
    "---\n",
    "Yes, this is as expected, because as the rank increases, by definition the score must decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9277b",
   "metadata": {},
   "source": [
    "### Additional Experiment\n",
    "\n",
    "Now, invoke the same RAG chain for the same queries, but vary the number of retrieved chunks (k) using the following values:\n",
    "\n",
    "[1, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bfc3e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** k = 1 *****\n",
      "\n",
      "Query: What section is BPE training from? Also list the examples used for this algorithm in the book.\n",
      "Answer: Based on the provided context:\n",
      "\n",
      "*   The BPE algorithm is mentioned in relation to **Fig. 2.6**, suggesting it is discussed in or around **Section 2.6**.\n",
      "*   The provided context **does not list any examples** used for this algorithm.\n",
      "\n",
      "Avg Cosine Sim: 0.7036\n",
      "------------------------------\n",
      "Query: What formula does the book use for the Minimum Edit Distance algorithm?\n",
      "Answer: I am sorry, but the provided context does not contain information about the formula used for the Minimum Edit Distance algorithm. It only mentions that the algorithm was named by Wagner and Fischer.\n",
      "\n",
      "Avg Cosine Sim: 0.8112\n",
      "------------------------------\n",
      "Query: What problems are highlighted in the book when dealing with scale in large n-gram models?\n",
      "Answer: When dealing with scale in large n-gram models, the book highlights that language models can be very large, which leads to **practical issues**.\n",
      "\n",
      "Avg Cosine Sim: 0.8347\n",
      "------------------------------\n",
      "Query: What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\n",
      "Answer: I am sorry, but the provided context does not contain information about a technique of visualizing a language model proposed by Shannon in 1948, nor does it list sections. The context only states that \"This technique of visualizing a language model by sampling was ﬁrst suggested\".\n",
      "\n",
      "Avg Cosine Sim: 0.7067\n",
      "------------------------------\n",
      "Query: What examples does the book use to demonstrate syntactic constituency?\n",
      "Answer: The provided context states that \"The focus of the last chapter was on context-free grammars and constituent-\", but it does not offer any specific examples used to demonstrate syntactic constituency.\n",
      "\n",
      "Avg Cosine Sim: 0.6735\n",
      "------------------------------\n",
      "\n",
      "***** k = 10 *****\n",
      "\n",
      "Query: What section is BPE training from? Also list the examples used for this algorithm in the book.\n",
      "Answer: BPE training is discussed in **Chapter 2**, specifically illustrated in **Figure 2.6** which describes \"The training part of the BPE algorithm\". Section **2.4.3 \"BPE in practice\"** also elaborates on BPE learning.\n",
      "\n",
      "The example used for this algorithm in the book is **sequences of ASCII**.\n",
      "\n",
      "Avg Cosine Sim: 0.6155\n",
      "------------------------------\n",
      "Query: What formula does the book use for the Minimum Edit Distance algorithm?\n",
      "Answer: The provided context mentions \"Figure 2.19 The minimum edit distance algorithm\" and \"return D[n,m]\" as part of its termination. However, the specific formula or steps of the algorithm itself, as presented in Figure 2.19, are not included in the provided text.\n",
      "\n",
      "Avg Cosine Sim: 0.7544\n",
      "------------------------------\n",
      "Query: What problems are highlighted in the book when dealing with scale in large n-gram models?\n",
      "Answer: When dealing with scale in large n-gram models, the book highlights:\n",
      "\n",
      "*   **Practical issues:** Language models can be very large, leading to practical problems.\n",
      "*   **Efficiency considerations:** Efficiency is an important concern when building large n-gram language models.\n",
      "\n",
      "Avg Cosine Sim: 0.6567\n",
      "------------------------------\n",
      "Query: What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\n",
      "Answer: Based on the provided context, there is no information about a technique of visualizing a language model proposed by Shannon in 1948.\n",
      "\n",
      "However, the context does mention \"sampling\" as a technique for visualizing a language model. Content relevant to this topic can be found in:\n",
      "\n",
      "*   **3.4 Sampling sentences from a language model**\n",
      "\n",
      "Avg Cosine Sim: 0.5482\n",
      "------------------------------\n",
      "Query: What examples does the book use to demonstrate syntactic constituency?\n",
      "Answer: Based on the provided context, there are no specific examples used to demonstrate syntactic constituency. The text mentions \"immediate-constituent analysis\" as a method of syntactic study and introduces constituency parsing, but it does not offer any illustrative examples.\n",
      "\n",
      "Avg Cosine Sim: 0.6113\n",
      "------------------------------\n",
      "\n",
      "***** k = 20 *****\n",
      "\n",
      "Query: What section is BPE training from? Also list the examples used for this algorithm in the book.\n",
      "Answer: BPE training is from section **2.4.1 BPE training**.\n",
      "\n",
      "The examples used for the BPE algorithm in the book include:\n",
      "*   Simple BPE learning from sequences of ASCII.\n",
      "*   The \"Book that flight\" example (illustrated in Fig. 19.13).\n",
      "\n",
      "Avg Cosine Sim: 0.5736\n",
      "------------------------------\n",
      "Query: What formula does the book use for the Minimum Edit Distance algorithm?\n",
      "Answer: The provided context defines the minimum edit distance conceptually as \"the minimum edit distance operations it takes to edit one into the other.\"\n",
      "\n",
      "While it doesn't provide a specific mathematical formula, it indicates that the algorithm is an example of a dynamic programming approach, with a termination step returning `D[n,m]`, suggesting the use of a matrix `D` to compute the distance. It also mentions computing the edit distance using specific costs for insertion (1), deletion (1), and substitution (sub-cost(x,x) = 0).\n",
      "\n",
      "Avg Cosine Sim: 0.6984\n",
      "------------------------------\n",
      "Query: What problems are highlighted in the book when dealing with scale in large n-gram models?\n",
      "Answer: The book highlights that when dealing with scale in large n-gram models, the primary problem is that language models can become \"very large,\" leading to \"practical issues.\"\n",
      "\n",
      "Avg Cosine Sim: 0.6204\n",
      "------------------------------\n",
      "Query: What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\n",
      "Answer: The technique of visualizing a language model proposed by Shannon in 1948 was **sampling from language models**.\n",
      "\n",
      "Content relevant to this topic can be found in section **3.4 Sampling sentences from a language model**.\n",
      "\n",
      "Avg Cosine Sim: 0.5282\n",
      "------------------------------\n",
      "Query: What examples does the book use to demonstrate syntactic constituency?\n",
      "Answer: Based on the provided context, the book defines syntactic constituency as \"the idea that groups of words can behave as single units,\" but it does not offer specific examples to demonstrate this concept within the given text. The song title \"Because the Night\" is an epigraph for Chapter 18, not an example used to illustrate syntactic constituency.\n",
      "\n",
      "Avg Cosine Sim: 0.5915\n",
      "------------------------------\n",
      "\n",
      "***** k = 50 *****\n",
      "\n",
      "Query: What section is BPE training from? Also list the examples used for this algorithm in the book.\n",
      "Answer: BPE training is from section **2.4.1**.\n",
      "\n",
      "The examples used for this algorithm in the book include:\n",
      "*   Simple BPE learning from **sequences of ASCII**.\n",
      "The text also mentions that it will show \"some examples of the industrial application of the BPE tokenizer,\" but specific examples are not listed in the provided context.\n",
      "\n",
      "Avg Cosine Sim: 0.5245\n",
      "------------------------------\n",
      "Query: What formula does the book use for the Minimum Edit Distance algorithm?\n",
      "Answer: The provided context mentions that the Minimum Edit Distance algorithm uses the **Levenshtein distance** as defined in **Eq. 2.20**.\n",
      "\n",
      "While the specific mathematical formula for Eq. 2.20 is not explicitly provided in the text, the context describes the algorithm as:\n",
      "\n",
      "*   A function `MIN-EDIT-DISTANCE (source, target)` that returns `min-distance`.\n",
      "*   It computes `D[n,m]`, where `D[i,j]` represents the edit distance between the first `i` characters of the source string and the first `j` characters of the target string.\n",
      "*   The full algorithm is shown in **Figure 2.19**.\n",
      "*   It defines the minimum edit distance as the minimum number of editing operations (insertion, deletion, substitution) required to change one string into the other.\n",
      "\n",
      "Avg Cosine Sim: 0.6080\n",
      "------------------------------\n",
      "Query: What problems are highlighted in the book when dealing with scale in large n-gram models?\n",
      "Answer: When dealing with scale in large n-gram models, the book highlights the following problems:\n",
      "\n",
      "*   **Practical issues due to their very large size:** Language models can become extremely large, leading to practical difficulties.\n",
      "*   **Efficiency considerations:** Building large n-gram language models requires careful attention to efficiency.\n",
      "*   **The number of parameters:** This is explicitly mentioned as one of the major problems with n-grams, which neural networks were developed to solve.\n",
      "\n",
      "Avg Cosine Sim: 0.5762\n",
      "------------------------------\n",
      "Query: What technique of visualizing a language model was proposed by Shannon in 1948? Furthermore, list the section which contains content relevant to this topic.\n",
      "Answer: The technique of visualizing a language model proposed by Shannon in 1948 was **sampling from language models**.\n",
      "\n",
      "Content relevant to this topic can be found in section **3.4 Sampling sentences from a language model**.\n",
      "\n",
      "Avg Cosine Sim: 0.5002\n",
      "------------------------------\n",
      "Query: What examples does the book use to demonstrate syntactic constituency?\n",
      "Answer: The book uses the sentence \"I wanted to go to London\" as an example of a syntactic phrase structure, which is directly related to the concept of syntactic constituency.\n",
      "\n",
      "Avg Cosine Sim: 0.5661\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "top_k_values = [1, 10, 20, 50]\n",
    "experiment_results = {}\n",
    "\n",
    "for k in top_k_values:\n",
    "    print(f\"\\n***** k = {k} *****\\n\")\n",
    "    current_k_answers = []\n",
    "    \n",
    "    for query in queries:\n",
    "        # Retrieve top-k docs and scores\n",
    "        docs_and_scores = vectorstore.similarity_search_with_score(query, k=k)\n",
    "        similarities = [1 - score for _, score in docs_and_scores]\n",
    "        avg_similarity = np.mean(similarities)\n",
    "        context_text = \"\\n\\n\".join([doc.page_content for doc, _ in docs_and_scores])\n",
    "        \n",
    "        answer = rag_chain.invoke({\n",
    "            \"context\": context_text,\n",
    "            \"question\": query\n",
    "        })\n",
    "\n",
    "        # Store result for this query\n",
    "        current_k_answers.append({\n",
    "            \"query\": query,\n",
    "            \"avg_similarity\": avg_similarity,\n",
    "            \"retrieved_docs\": docs_and_scores,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "        \n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Answer: {answer}\\n\")\n",
    "        print(f\"Avg Cosine Sim: {avg_similarity:.4f}\\n\" + \"-\"*30 )\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "    experiment_results[k] = current_k_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fdfe8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k: 1\n",
      "  Query 1: Avg similarity = 0.7036\n",
      "  Query 2: Avg similarity = 0.8112\n",
      "  Query 3: Avg similarity = 0.8347\n",
      "  Query 4: Avg similarity = 0.7067\n",
      "  Query 5: Avg similarity = 0.6735\n",
      "------------------------------\n",
      "Top-k: 10\n",
      "  Query 1: Avg similarity = 0.6155\n",
      "  Query 2: Avg similarity = 0.7544\n",
      "  Query 3: Avg similarity = 0.6567\n",
      "  Query 4: Avg similarity = 0.5482\n",
      "  Query 5: Avg similarity = 0.6113\n",
      "------------------------------\n",
      "Top-k: 20\n",
      "  Query 1: Avg similarity = 0.5736\n",
      "  Query 2: Avg similarity = 0.6984\n",
      "  Query 3: Avg similarity = 0.6204\n",
      "  Query 4: Avg similarity = 0.5282\n",
      "  Query 5: Avg similarity = 0.5915\n",
      "------------------------------\n",
      "Top-k: 50\n",
      "  Query 1: Avg similarity = 0.5245\n",
      "  Query 2: Avg similarity = 0.6080\n",
      "  Query 3: Avg similarity = 0.5762\n",
      "  Query 4: Avg similarity = 0.5002\n",
      "  Query 5: Avg similarity = 0.5661\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k, answers in experiment_results.items():\n",
    "    print(f\"Top-k: {k}\")\n",
    "    for i, res in enumerate(answers):\n",
    "        print(f\"  Query {i+1}: Avg similarity = {res['avg_similarity']:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a661af9",
   "metadata": {},
   "source": [
    "### **Reflective Question** How does changing the value of k affect the overall quality of results?\n",
    "\n",
    "**Answer:**\n",
    "As k increases, the average similarity of the results decreases, since lower ranked chunks are also included as context.\n",
    "\n",
    "At lower k (1, 10), the answers were generally unhelpful and were not satisfactory; at higher k, the system was able to answer queries which required a larger context base.\n",
    "\n",
    "However, the higher the value of k, the greater the uncertainty of results and higher the noise, since less-relevant documenrts are being fetched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f10b64",
   "metadata": {},
   "source": [
    "# Task 4: AI-as-a-Judge\n",
    "\n",
    "In this task, you will design an **LLM-based evaluation and reflection loop** for a Retrieval-Augmented Generation (RAG) system. Your goal is to implement a **Critic–Reflector mechanism** that evaluates, scores, and iteratively improves the performance of your RAG pipeline using the following dataset:\n",
    "\n",
    "> **Dataset:** [Neural Bridge RAG Dataset](https://huggingface.co/datasets/neural-bridge/rag-dataset-12000)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "You will:\n",
    "1. Implement a **Critic** agent that assesses your RAG model’s answers.  \n",
    "2. Use a **Reflector** agent to analyze the Critic’s feedback and optimize the RAG Generator’s performance across multiple iterations.  \n",
    "3. Visualize how the **reward (Critic rating)** evolves as your system self-tunes.\n",
    "\n",
    "---\n",
    "\n",
    "## System Components\n",
    "\n",
    "| Component | Model | Role |\n",
    "|------------|--------|------|\n",
    "| **Generator** | Gemini 2.0 Flash | Produces answers using your RAG pipeline |\n",
    "| **Critic** | Gemini 2.5 Pro | Evaluates Generator’s output and provides rewards |\n",
    "| **Reflector** | Gemini 2.5 Pro | Adjusts the Generator’s configuration to maximize reward |\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1 — Setting Up the Critic\n",
    "\n",
    "1. Configure an **LLM Critic** using the **Gemini 2.5 Pro** model (or a higher version than your RAG Generator).  \n",
    "   - Set the **temperature** parameter to `0` for deterministic evaluation.  \n",
    "\n",
    "2. The Critic should take the following as input:\n",
    "   - The user query (question)  \n",
    "   - The retrieved context/documents  \n",
    "   - The Generator’s response  \n",
    "\n",
    "3. The Critic must output:\n",
    "   - An **expected (ideal) answer**\n",
    "   - A **numerical rating (out of 10)** indicating how well the Generator’s response aligns with the expected output  \n",
    "\n",
    "4. Use **few-shot prompting** to guide the Critic’s evaluations.  \n",
    "   - Collect several sample query–retrieval–response–rating pairs by manually evaluating model outputs from the dataset.  \n",
    "   - Provide these examples in your Critic’s prompt to calibrate its scoring behavior.\n",
    "\n",
    "> 💡 *Tip:* This few-shot calibration step should be clearly shown in your code before running the evaluation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e073355",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIC_MODEL = \"gemini-2.5-pro\"\n",
    "REFLECTOR_MODEL = \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d019c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset = load_dataset(\"neural-bridge/rag-dataset-12000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce66a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Run the Critic with a few examples from the dataset, and evaluate the outputs. \n",
    "#    You should cherry-pick the best outputs from the bunch, and use them as your few-shot samples for the following task.\n",
    "\n",
    "# had little time, so I had an LLM make these few shot examples...sorry :(\n",
    "\n",
    "fewshot_example1_query = \"What is the main limitation of N-gram language models?\"\n",
    "fewshot_example1_context = \"The primary limitation of N-gram models is sparsity. As N increases, the number of possible n-grams grows exponentially, making it difficult to estimate probabilities reliably from limited training data.\"\n",
    "fewshot_example1_answer = \"The main limitation is sparsity. Because the number of parameters grows exponentially with N, it becomes hard to estimate probabilities from limited data.\"\n",
    "fewshot_example1_rating = 10\n",
    "fewshot_example1_explanation = \"The answer is accurate, complete, and directly supported by the context.\"\n",
    "\n",
    "fewshot_example2_query = \"Who introduced the Transformer architecture?\"\n",
    "fewshot_example2_context = \"The Transformer architecture was introduced by Vaswani et al. in the 2017 paper 'Attention Is All You Need'. It relies entirely on self-attention mechanisms.\"\n",
    "fewshot_example2_answer = \"The Transformer was proposed by Yann LeCun in 1998 as an improvement to Convolutional Neural Networks for digit recognition.\"\n",
    "fewshot_example2_rating = 1\n",
    "fewshot_example2_explanation = \"The answer is factually incorrect and contradicts the provided context (Vaswani vs LeCun).\"\n",
    "\n",
    "fewshot_example_3_query = \"How is the TF-IDF score calculated?\"\n",
    "fewshot_example_3_context = \"TF-IDF is calculated as the product of Term Frequency (TF) and Inverse Document Frequency (IDF). TF measures how often a term appears in a document, while IDF downweights terms that appear frequently across the entire corpus.\"\n",
    "fewshot_example_3_answer = \"It is calculated by multiplying two statistics together that measure how important a word is.\"\n",
    "fewshot_example_3_rating = 5\n",
    "fewshot_example_3_explanation = \"The answer is technically true but vague. It fails to name 'Term Frequency' and 'Inverse Document Frequency' or explain what they do, despite that info being in the context.\"\n",
    "\n",
    "# Compose few-shot example text\n",
    "fewshot_examples_text = f\"\"\"\n",
    "Example 1:\n",
    "Query: {fewshot_example1_query}\n",
    "Context: {fewshot_example1_context}\n",
    "Generator answer: {fewshot_example1_answer}\n",
    "Expected (ideal) answer: {fewshot_example1_answer}\n",
    "Rating: {fewshot_example1_rating}\n",
    "Explanation: {fewshot_example1_explanation}\n",
    "\n",
    "Example 2:\n",
    "Query: {fewshot_example2_query}\n",
    "Context: {fewshot_example2_context}\n",
    "Generator answer: {fewshot_example2_answer}\n",
    "Expected (ideal) answer: The Transformer was introduced by Vaswani et al. in the 2017 paper 'Attention Is All You Need'.\n",
    "Rating: {fewshot_example2_rating}\n",
    "Explanation: {fewshot_example2_explanation}\n",
    "\n",
    "Example 3:\n",
    "Query: {fewshot_example_3_query}\n",
    "Context: {fewshot_example_3_context}\n",
    "Generator answer: {fewshot_example_3_answer}\n",
    "Expected (ideal) answer: TF-IDF is calculated as TF * IDF, where TF measures term frequency in a document and IDF downweights common terms across the corpus.\n",
    "Rating: {fewshot_example_3_rating}\n",
    "Explanation: {fewshot_example_3_explanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496fdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the critic\n",
    "critic_system_prompt = \"\"\"\n",
    "Evaluate the output of a RAG system, along with the user quey and the contexts.\n",
    "Your evaluation should output:\n",
    "1) An expected (ideal) answer for the user query.\n",
    "2) A **numerical rating (out of 10)** indicating how well the Generator’s response aligns with the expected output.\n",
    "\n",
    "Use these examples to guide you on how to do this task:\n",
    "{fewshot_examples_text}\n",
    "\n",
    "\n",
    "Output should be in a JSON format with keys: expected_answer, rating. Only these two must be output as a JSON object!\n",
    "\"\"\"\n",
    "\n",
    "critic_user_prompt = \"\"\"\n",
    "Evaluate the following RAG system output.\n",
    "\n",
    "User Query:\n",
    "{query}\n",
    "\n",
    "Retrieved Context:\n",
    "{context}\n",
    "\n",
    "Generator's Answer:\n",
    "{generator_answer}\n",
    "\n",
    "Output ONLY a JSON object with two keys:\n",
    "- expected_answer: a short, clear ideal answer (1-2 sentences)\n",
    "- rating: an integer from 0 to 10\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfd8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", critic_system_prompt),\n",
    "    (\"user\", critic_user_prompt)\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "critic_llm = ChatGoogleGenerativeAI(model=CRITIC_MODEL, temperature=0)\n",
    "\n",
    "critic_chain = critic_prompt_template | critic_llm | json_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbe6f6",
   "metadata": {},
   "source": [
    "## Part 2 — Designing the Reflector\n",
    "\n",
    "The **Reflector** takes as input:\n",
    "- The original user query  \n",
    "- The Generator’s response  \n",
    "- The Critic’s expected response and rating  \n",
    "- Any other hyperparameters or metrics you deem useful  \n",
    "\n",
    "Using this information, the Reflector should:\n",
    "- Modify or tune the Generator’s configuration to **maximize the Critic’s rating (reward)** over time.  \n",
    "- The Reflector may adjust:\n",
    "  - The Generator’s **system or user messages** (prompt engineering)  \n",
    "  - The **text splitter parameters** (e.g., `chunk_size`, `chunk_overlap`)  \n",
    "  - Any other relevant **retriever or generator hyperparameters** that can improve the RAG pipeline’s accuracy or coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d47b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize the Reflector\n",
    "reflector_system_prompt = \"\"\"You are an expert AI Optimization Engineer for RAG pipelines.\n",
    "Your goal is to tune hyperparameters to maximize the Critic's rating (target: 10/10).\n",
    "\n",
    "You can tune two parameters:\n",
    "1. `k` (integer, 1-10): Number of chunks to retrieve.\n",
    "2. `system_message` (string): The instruction given to the Generator.\n",
    "\n",
    "**Analysis Strategy:**\n",
    "Look at the history of iterations. Compare the **Generator Answer** to the **Critic's Expected Answer**:\n",
    "- If the Generator missed details present in the Expected Answer -> **Increase `k`** or tell the system to be more detailed.\n",
    "- If the Generator included facts NOT in the Expected Answer (Hallucination) -> **Restrict the system_message** (e.g., \"Stick strictly to context\").\n",
    "- If the Rating is low (0-5) -> Make significant changes.\n",
    "- If the Rating is high (8-9) -> Make minor refinements.\n",
    "\n",
    "**Output Format:**\n",
    "Return ONLY a JSON object with these keys:\n",
    "{\n",
    "    \"k\": <integer>,\n",
    "    \"system_message\": \"<string>\",\n",
    "    \"reasoning\": \"<brief explanation of why you made these changes based on the history>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "reflector_user_prompt = \"\"\"\n",
    "Review the optimization history below and suggest the next configuration.\n",
    "\n",
    "Optimization History:\n",
    "{history}\n",
    "\n",
    "Suggest the next configuration (JSON):\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbca8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflector_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", reflector_system_prompt),\n",
    "    (\"user\", reflector_user_prompt)\n",
    "])\n",
    "\n",
    "\n",
    "reflector_llm = ChatGoogleGenerativeAI(model=REFLECTOR_MODEL, temperature=0)\n",
    "reflector_parser = JsonOutputParser()\n",
    "\n",
    "reflector_chain = reflector_prompt_template | reflector_llm | reflector_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c9488",
   "metadata": {},
   "source": [
    "## Part 3 — Iterative Optimization Loop\n",
    "\n",
    "1. Run your **Critic–Reflector feedback loop** for **30 iterations**.  \n",
    "2. After each iteration:\n",
    "   - Re-run the Generator with the updated configuration.  \n",
    "   - Re-evaluate using the Critic.  \n",
    "   - Record the **reward score** assigned by the Critic.  \n",
    "\n",
    "3. Plot the **reward progression** over the 30 iterations to visualize how your RAG system improves (or regresses) with reflection-driven optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c0cb2",
   "metadata": {},
   "source": [
    "Had to get an LLM to code this up, was taking too long :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de345a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Integrate the Critic and Reflector with the RAG system, and run the loop\n",
    "\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# first 10 datapoints\n",
    "dataset_subset = rag_dataset['train'][:10]\n",
    "\n",
    "\n",
    "print(\"Indexing subset contexts into temporary VectorStore...\")\n",
    "subset_docs = []\n",
    "test_queries = []\n",
    "ground_truths = []\n",
    "\n",
    "for row in dataset_subset:\n",
    "\n",
    "    doc = Document(page_content=row['context'], metadata={\"source\": \"rag_dataset\"})\n",
    "    subset_docs.append(doc)\n",
    "    \n",
    "    # Store query and answer for evaluation\n",
    "    test_queries.append(row['question'])\n",
    "    ground_truths.append(row['answer'])\n",
    "\n",
    "# Create a new, small vectorstore for this experiment\n",
    "# (We reuse the hf_embeddings from Task 3)\n",
    "task4_vectorstore = Chroma.from_documents(\n",
    "    documents=subset_docs,\n",
    "    embedding=hf_embeddings,\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# --- 3. Run Optimization Loop ---\n",
    "iterations = 10 # Running 10 iterations for demonstration\n",
    "current_config = {\n",
    "    \"k\": 1,  # Start suboptimal to show improvement\n",
    "    \"system_message\": \"You are a helpful assistant.\"\n",
    "}\n",
    "\n",
    "history_log = []\n",
    "reward_history = []\n",
    "\n",
    "print(f\"\\n🚀 Starting Optimization Loop on {len(test_queries)} Dataset Queries...\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "for i in range(iterations):\n",
    "    iteration_scores = []\n",
    "    \n",
    "    # --- Batch Evaluation ---\n",
    "    # We run the current config on all 10 dataset queries\n",
    "    for q_idx, query in enumerate(test_queries):\n",
    "        try:\n",
    "            # A. Generator Step\n",
    "            retriever = task4_vectorstore.as_retriever(search_kwargs={\"k\": int(current_config['k'])})\n",
    "            \n",
    "            rag_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", current_config['system_message'] + \"\\n\\nContext:\\n{context}\"),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ])\n",
    "            \n",
    "            docs = retriever.invoke(query)\n",
    "            context_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "            \n",
    "            gen_chain = rag_prompt | llm | StrOutputParser()\n",
    "            generator_answer = gen_chain.invoke({\"context\": context_text, \"question\": query})\n",
    "            \n",
    "            # B. Critic Step\n",
    "            # Note: We pass the generated context, but the Critic checks against the GENERATOR'S logic.\n",
    "            # Ideally, the Critic uses the 'Ground Truth' from the dataset as the 'Expected Answer'\n",
    "            # But our Critic is designed to generate its own Expected Answer via LLM. \n",
    "            # We will stick to the LLM Critic workflow for consistency with the prompt.\n",
    "            critic_output = critic_chain.invoke({\n",
    "                \"query\": query,\n",
    "                \"context\": context_text,\n",
    "                \"generator_answer\": generator_answer\n",
    "            })\n",
    "            \n",
    "            score = critic_output['rating']\n",
    "            iteration_scores.append(score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on Q{q_idx}: {e}\")\n",
    "            iteration_scores.append(0)\n",
    "\n",
    "    # Calculate Avg Score for this Config\n",
    "    avg_score = np.mean(iteration_scores) if iteration_scores else 0\n",
    "    reward_history.append(avg_score)\n",
    "    \n",
    "    print(f\"Iter {i+1} | k={current_config['k']} | Avg Score: {avg_score:.2f}/10\")\n",
    "\n",
    "    # Store history for Reflector\n",
    "    step_summary = {\n",
    "        \"iteration\": i + 1,\n",
    "        \"config\": current_config.copy(),\n",
    "        \"avg_score\": avg_score\n",
    "    }\n",
    "    history_log.append(step_summary)\n",
    "\n",
    "    # --- Reflector Step ---\n",
    "    if i < iterations - 1:\n",
    "        # Format history for Reflector\n",
    "        history_str = \"\"\n",
    "        for item in history_log[-3:]:\n",
    "             history_str += f\"\\nIter {item['iteration']}: Config={item['config']}, Avg Score={item['avg_score']:.2f}\"\n",
    "        \n",
    "        try:\n",
    "            reflector_response = reflector_chain.invoke({\"history\": history_str})\n",
    "            \n",
    "            new_k = int(reflector_response.get('k', current_config['k']))\n",
    "            # Limit k to the size of our small dataset (10) to avoid errors\n",
    "            new_k = max(1, min(10, new_k))\n",
    "            \n",
    "            current_config = {\n",
    "                \"k\": new_k,\n",
    "                \"system_message\": reflector_response.get('system_message', current_config['system_message'])\n",
    "            }\n",
    "            # print(f\"   >>> Reflector Update: k -> {new_k}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Reflector Error: {e}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, iterations + 1), reward_history, marker='o', color='#FF5722', linewidth=2)\n",
    "plt.title(f'Optimization on Neural Bridge Dataset ({len(test_queries)} samples)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average Critic Score')\n",
    "plt.ylim(0, 10.5)\n",
    "plt.grid(True)\n",
    "plt.show()on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed89ebb",
   "metadata": {},
   "source": [
    "#### **Reflective Questions:**\n",
    "\n",
    "##### 1. Did you see any improvements in the pipeline's performance? Explain why or why not? Explain the general trend of reward progression here.\n",
    "\n",
    "##### 2. Are LLMs a reliable source for scoring purposes? Explain why did we initialize the temperature value to 0 for these tasks?\n",
    "\n",
    "##### 3. Which hyperparameters had the most significant impact in optimizing the RAG performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-pa4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
